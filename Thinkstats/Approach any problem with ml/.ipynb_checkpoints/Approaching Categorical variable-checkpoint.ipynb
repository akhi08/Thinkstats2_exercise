{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21fca4b3-e935-43bc-9bc1-61d710caa9b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3811a7ee-23a5-4be2-a4f2-e179e9630910",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/akhichoudhary/STATS/Thinkstats/Thinkstats2_exercise/Thinkstats/Approach any problem with ml\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f77896b4-af67-4422-a296-3ca2226dd4f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "file_path = '/Users/akhichoudhary/STATS/Thinkstats/Thinkstats2_exercise/Thinkstats/Approach any problem with ml/car-in-the-dat.zip'\n",
    "print(os.path.exists(file_path))  # Should return True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1759db9b-71ea-4d30-add1-0fcd80900cfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import zipfile\n",
    "# import pandas as pd\n",
    "\n",
    "    # df=pd.read_csv('/Users/akhichoudhary/STATS/Thinkstats/Thinkstats2_exercise/Thinkstats/Approach any problem with ml/data/train.csv')\n",
    "\n",
    "# or-------\n",
    "\n",
    "# # Path to the ZIP folder\n",
    "# zip_path = '/Users/akhichoudhary/STATS/Thinkstats/Thinkstats2_exercise/Thinkstats/Approach any problem with ml/cat-in-the-dat.zip'\n",
    "\n",
    "# # Open the zip and list contents\n",
    "# with zipfile.ZipFile(zip_path, 'r') as z:\n",
    "#     print(\"Files in ZIP:\", z.namelist())  # View files like 'train.csv', 'test.csv'\n",
    "\n",
    "#     # Load specific CSVs\n",
    "#     with z.open('train.csv') as f:\n",
    "#         train_df = pd.read_csv(f)\n",
    "\n",
    "#     with z.open('test.csv') as f:\n",
    "#         test_df = pd.read_csv(f)\n",
    "\n",
    "# # Now you can use train_df and test_df as usual\n",
    "# # print(train_df.head())\n",
    "# # print(test_df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a7c99ce-39a7-4800-96ae-e2507c491b29",
   "metadata": {},
   "source": [
    "## Start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e03b6907-55e6-46a7-a008-8a7db41b6b80",
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping={\n",
    "    \"Freezing\": 0,\n",
    "    \"Warm\": 1,\n",
    "    \"Cold\": 2,\n",
    "    \"Boiling Hot\": 3,\n",
    "    \"Hot\": 4,\n",
    "    \"Lava Hot\": 5\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "54d48562-1cf7-46b6-96f8-5a3eb367b85c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ord_2\n",
       "Freezing       99816\n",
       "Lava Hot       63908\n",
       "Boiling Hot    60627\n",
       "Cold           33768\n",
       "Hot            22227\n",
       "Warm           19654\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.ord_2.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "468fbed4-1268-4ff7-83c3-6ca31e439f7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.loc[:,\"ord_2\"]=train_df.ord_2.map(mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c9bf7cd7-6080-47bd-8bb1-7deba3f5a535",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ord_2\n",
       "0    99816\n",
       "5    63908\n",
       "3    60627\n",
       "2    33768\n",
       "4    22227\n",
       "1    19654\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.ord_2.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b733e69b-c2b1-487f-8bc6-de1119276711",
   "metadata": {},
   "source": [
    "## ~ LabelEncoder,OneHotEncoder,Binarization\n",
    "- above same encoding into numerical value can be done by LabelEncoder from scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d98e5baa-1255-47b0-8dc9-9a09a679dc6f",
   "metadata": {},
   "source": [
    "### Label Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5c498bab-5be5-4c5b-a64a-2d71137fe765",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "df=pd.read_csv('/Users/akhichoudhary/STATS/Thinkstats/Thinkstats2_exercise/Thinkstats/Approach any problem with ml/data/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0c39969d-9144-4ea8-945b-9906092ac7ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[:,\"ord_2\"]=df.ord_2.fillna(\"NONE\")\n",
    "# LabelEncoder from scikit-learn does not handle NaN values, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5b95b182-b75f-4164-9523-3a9ec3065b22",
   "metadata": {},
   "outputs": [],
   "source": [
    "lbl_enc=preprocessing.LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c54cadf0-1f1f-467d-a1e7-77597bb8b2f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit label encoder and transform values on ord_2 column\n",
    "# P.S: do not use this directly. fit first, then transform\n",
    "df.loc[:,\"ord_2\"]=lbl_enc.fit_transform(df.ord_2.values)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "61396b4d-433b-481f-8cd2-2a24a57ee0a2",
   "metadata": {},
   "source": [
    "# labelEncoder can be used \n",
    "• Decision trees\n",
    "• Random forest\n",
    "• Extra Trees\n",
    "• Or any kind of boosted trees model\n",
    "o XGBoost\n",
    "o GBM\n",
    "o LightGBM\n",
    "This type of encoding cannot be used in linear models, support vector machines or\n",
    "neural networks as they expect data to be normalized (or standardized)."
   ]
  },
  {
   "cell_type": "raw",
   "id": "cf7ccbe4-a870-4ae3-a1e8-f5ad7e1ec73c",
   "metadata": {},
   "source": [
    "✅ What it's saying:\n",
    "1. For Tree-Based Models (e.g., Decision Trees, Random Forest, XGBoost, LightGBM):\n",
    "You can use Label Encoding or even leave NaNs in some cases.\n",
    "\n",
    "Tree models do not require one-hot or binarized encoding because they can naturally handle splits based on categorical values.\n",
    "\n",
    "That’s why it's okay to use LabelEncoder (after handling NaNs properly) or even ordinal encoding.\n",
    "\n",
    "2. For Linear Models / SVMs / Neural Networks:\n",
    "You should not use Label Encoding because it introduces an artificial ordinal relationship between categories (e.g., A=0, B=1, C=2 suggests C > B > A which may not be true).\n",
    "\n",
    "Instead, you should use One-Hot Encoding or Binarization.\n",
    "\n",
    "Binarization is converting each category into a binary format (e.g., A → [0 0 1], B → [0 1 0], C → [1 0 0]).\n",
    "\n",
    "This is often done in sparse format to save memory, since many values will be 0.\n",
    "\n",
    "❓ So is it suggesting binarization for linear models?\n",
    "Yes. Specifically, it is saying:\n",
    "\n",
    "Use binarization/one-hot encoding for models that require numerical input to be normalized:\n",
    "Linear Regression, Logistic Regression, Support Vector Machines (SVM), and Neural Networks.\n",
    "\n",
    "Continue with Label Encoding or Ordinal Encoding for tree-based models, which can handle this directly."
   ]
  },
  {
   "cell_type": "raw",
   "id": "bc854f6f-709b-4af9-b80d-fd4a41fc03ba",
   "metadata": {},
   "source": [
    "| Model Type          | Recommended Encoding     | Notes                             |\n",
    "| ------------------- | ------------------------ | --------------------------------- |\n",
    "| Decision Tree       | Label Encoding / Ordinal | Can handle NaNs                   |\n",
    "| Random Forest       | Label Encoding / Ordinal | Can handle categories             |\n",
    "| XGBoost / LightGBM  | Label Encoding / Ordinal | Best with category-aware encoding |\n",
    "| Linear Regression   | One-Hot / Binarization   | Needs numeric & normalized data   |\n",
    "| Logistic Regression | One-Hot / Binarization   | Same                              |\n",
    "| SVM                 | One-Hot / Binarization   | Same                              |\n",
    "| Neural Networks     | One-Hot / Binarization   | Same                              |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb35a159-2770-43ee-86db-46f16262f249",
   "metadata": {},
   "source": [
    "-  checking the bytes used by different techniques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a7a8df34-fa3f-4716-bb2f-ad26247e5682",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "example=np.array([\n",
    "    [0,0,1],\n",
    "    [1,0,0],\n",
    "    [1,0,1]]\n",
    ")\n",
    "print(example.nbytes)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "8a47e46a-ab83-4417-9d5f-1b2a756e5149",
   "metadata": {},
   "source": [
    "One way to\n",
    "represent this matrix only with ones would be some kind of dictionary method in\n",
    "which keys are indices of rows and columns and value is 1:\n",
    "══════════════════\n",
    "(0, 2) 1\n",
    "(1, 0) 1\n",
    "(2, 0) 1\n",
    "(2, 2) 1\n",
    "══════════════════"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ec6c77d6-5c7b-42ad-a9b1-d520ea9cac7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32\n"
     ]
    }
   ],
   "source": [
    "from scipy import sparse\n",
    "\n",
    "example=np.array(\n",
    "    [[0, 0, 1],\n",
    "[1, 0, 0],\n",
    "[1, 0, 1]]\n",
    ")\n",
    "\n",
    "sparse_example=sparse.csr_matrix(example)\n",
    "print(sparse_example.data.nbytes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a35c3e5-ea59-442f-a07d-f663e42ef1b7",
   "metadata": {},
   "source": [
    "- The total size of the sparse csr matrix is the sum of three values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3efb6518-e8a4-43a9-8c95-df9dbb7e2b73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    sparse_example.data.nbytes +\n",
    "sparse_example.indptr.nbytes +\n",
    "sparse_example.indices.nbytes\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c1454018-0f7c-4e70-b93e-ec4b16fb7707",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of dense array: 8000000000\n",
      "Size of sparse array: 399997896\n",
      "Full size of sparse array: 600036848\n"
     ]
    }
   ],
   "source": [
    "# number of rows\n",
    "n_rows = 10000\n",
    "# number of columns\n",
    "n_cols = 100000\n",
    "# create random binary matrix with only 5% values as 1s\n",
    "example = np.random.binomial(1, p=0.05, size=(n_rows, n_cols))\n",
    "# print size in bytes\n",
    "print(f\"Size of dense array: {example.nbytes}\")\n",
    "# convert numpy array to sparse CSR matrix\n",
    "sparse_example = sparse.csr_matrix(example)\n",
    "# print size of this sparse matrix\n",
    "print(f\"Size of sparse array: {sparse_example.data.nbytes}\")\n",
    "full_size = (\n",
    "sparse_example.data.nbytes +\n",
    "sparse_example.indptr.nbytes +\n",
    "sparse_example.indices.nbytes\n",
    ")\n",
    "# print full size of this sparse matrix\n",
    "print(f\"Full size of sparse array: {full_size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4dc0d379-955f-4616-8394-145abeb6fe08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# So, dense array takes ~8000MB or approximately 8GB of memory. The sparse\n",
    "# array, on the other hand, takes only 399MB of memory.\n",
    "# And, that’s why we prefer sparse arrays over dense whenever we have a lot of zeros\n",
    "# in our features."
   ]
  },
  {
   "cell_type": "raw",
   "id": "b083ff76-3823-4e02-b2ed-4d01ad75ec1f",
   "metadata": {},
   "source": [
    "Even though the sparse representation of binarized features takes much less\n",
    "memory than its dense representation, there is another transformation for\n",
    "categorical variables that takes even less memory. This is known as One Hot\n",
    "Encoding.\n",
    "One hot encoding is a binary encoding too in the sense that there are only two\n",
    "values, 0s and 1s."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d65aa563-0337-4985-aac7-2a2b85d6479a",
   "metadata": {},
   "source": [
    "### Binarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "31eed1d8-9f71-4ee7-830a-52b183c3b953",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of dense array: 144\n",
      "Size of sparse array: 24\n",
      "Full size of sparse array: 52\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy import sparse\n",
    "# create binary matrix\n",
    "example = np.array(\n",
    "[\n",
    "[0, 0, 0, 0, 1, 0],\n",
    "[0, 1, 0, 0, 0, 0],\n",
    "[1, 0, 0, 0, 0, 0]\n",
    "]\n",
    ")\n",
    "# print size in bytes\n",
    "print(f\"Size of dense array: {example.nbytes}\")\n",
    "# convert numpy array to sparse CSR matrix\n",
    "sparse_example = sparse.csr_matrix(example)\n",
    "# print size of this sparse matrix\n",
    "print(f\"Size of sparse array: {sparse_example.data.nbytes}\")\n",
    "full_size = (\n",
    "sparse_example.data.nbytes +\n",
    "sparse_example.indptr.nbytes +\n",
    "sparse_example.indices.nbytes\n",
    ")\n",
    "# print full size of this sparse matrix\n",
    "print(f\"Full size of sparse array: {full_size}\")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "a6830866-ba05-4739-9f2d-2611d9f7cabf",
   "metadata": {},
   "source": [
    "We see that the dense array size is much larger than the one with binarization.\n",
    "However, the size of the sparse array is much less. Let’s try this with a much larger\n",
    "array. In this example, we will use OneHotEncoder from scikit-learn to transform\n",
    "our feature array with 1001 categories into dense and sparse matrices."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40695d83-b6ed-4910-9072-d7d1278f3c4d",
   "metadata": {},
   "source": [
    "### OneHotEncoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1e037532-ed0e-4c17-a64c-e67b376b7a07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of dense array: 8000000000\n",
      "Size of sparse array: 8000000\n",
      "Full size of sparse array: 16000004\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "# create random 1-d array with 1001 different categories (int)\n",
    "example = np.random.randint(1000, size=1000000)\n",
    "# initialize OneHotEncoder from scikit-learn\n",
    "# keep sparse = False to get dense array\n",
    "ohe = preprocessing.OneHotEncoder(sparse_output=False)\n",
    "# fit and transform data with dense one hot encoder\n",
    "ohe_example = ohe.fit_transform(example.reshape(-1, 1))\n",
    "# print size in bytes for dense array\n",
    "print(f\"Size of dense array: {ohe_example.nbytes}\")\n",
    "# initialize OneHotEncoder from scikit-learn\n",
    "# keep sparse = True to get sparse array\n",
    "ohe = preprocessing.OneHotEncoder(sparse_output=True)\n",
    "# fit and transform data with sparse one-hot encoder\n",
    "ohe_example = ohe.fit_transform(example.reshape(-1, 1))\n",
    "# print size of this sparse matrix\n",
    "print(f\"Size of sparse array: {ohe_example.data.nbytes}\")\n",
    "full_size = (\n",
    "ohe_example.data.nbytes +\n",
    "ohe_example.indptr.nbytes + ohe_example.indices.nbytes\n",
    ")\n",
    "# print full size of this sparse matrix\n",
    "print(f\"Full size of sparse array: {full_size}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9d3555c-e0c9-45d8-bda1-b74f2e761aa8",
   "metadata": {},
   "source": [
    "### Data manipulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "21f4ed74-f7e7-4985-b85a-f9243f58002c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         33768\n",
       "1         22227\n",
       "2         63908\n",
       "3         60627\n",
       "4         99816\n",
       "          ...  \n",
       "299995    99816\n",
       "299996    99816\n",
       "299997    60627\n",
       "299998    60627\n",
       "299999    99816\n",
       "Name: id, Length: 300000, dtype: int64"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby([\"ord_2\"])[\"id\"].transform(\"count\")\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "050d995d-b20e-46a4-8dfe-9c65e7f69514",
   "metadata": {},
   "source": [
    "It adds a new column (or Series) that shows, for each row in df, how many rows have the same ord_2 value — by counting the number of occurrences of each value in the \"ord_2\" column using the \"id\" column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "706fa7e9-56ce-45d0-8309-45fed291e553",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ord_1</th>\n",
       "      <th>ord_2</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Contributor</td>\n",
       "      <td>0</td>\n",
       "      <td>8692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Contributor</td>\n",
       "      <td>1</td>\n",
       "      <td>4842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Contributor</td>\n",
       "      <td>2</td>\n",
       "      <td>14284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Contributor</td>\n",
       "      <td>3</td>\n",
       "      <td>3122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Contributor</td>\n",
       "      <td>4</td>\n",
       "      <td>9074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Contributor</td>\n",
       "      <td>5</td>\n",
       "      <td>2857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Expert</td>\n",
       "      <td>0</td>\n",
       "      <td>4980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Expert</td>\n",
       "      <td>1</td>\n",
       "      <td>2850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Expert</td>\n",
       "      <td>2</td>\n",
       "      <td>8432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Expert</td>\n",
       "      <td>3</td>\n",
       "      <td>1887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Expert</td>\n",
       "      <td>4</td>\n",
       "      <td>5274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Expert</td>\n",
       "      <td>5</td>\n",
       "      <td>1642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Grandmaster</td>\n",
       "      <td>0</td>\n",
       "      <td>15719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Grandmaster</td>\n",
       "      <td>1</td>\n",
       "      <td>8702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Grandmaster</td>\n",
       "      <td>2</td>\n",
       "      <td>25620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Grandmaster</td>\n",
       "      <td>3</td>\n",
       "      <td>5697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Grandmaster</td>\n",
       "      <td>4</td>\n",
       "      <td>16617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Grandmaster</td>\n",
       "      <td>5</td>\n",
       "      <td>5073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Master</td>\n",
       "      <td>0</td>\n",
       "      <td>5720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Master</td>\n",
       "      <td>1</td>\n",
       "      <td>3129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Master</td>\n",
       "      <td>2</td>\n",
       "      <td>9401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Master</td>\n",
       "      <td>3</td>\n",
       "      <td>2069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Master</td>\n",
       "      <td>4</td>\n",
       "      <td>5882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Master</td>\n",
       "      <td>5</td>\n",
       "      <td>1852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Novice</td>\n",
       "      <td>0</td>\n",
       "      <td>25516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Novice</td>\n",
       "      <td>1</td>\n",
       "      <td>14245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Novice</td>\n",
       "      <td>2</td>\n",
       "      <td>42079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Novice</td>\n",
       "      <td>3</td>\n",
       "      <td>9452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Novice</td>\n",
       "      <td>4</td>\n",
       "      <td>27061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Novice</td>\n",
       "      <td>5</td>\n",
       "      <td>8230</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          ord_1  ord_2  count\n",
       "0   Contributor      0   8692\n",
       "1   Contributor      1   4842\n",
       "2   Contributor      2  14284\n",
       "3   Contributor      3   3122\n",
       "4   Contributor      4   9074\n",
       "5   Contributor      5   2857\n",
       "6        Expert      0   4980\n",
       "7        Expert      1   2850\n",
       "8        Expert      2   8432\n",
       "9        Expert      3   1887\n",
       "10       Expert      4   5274\n",
       "11       Expert      5   1642\n",
       "12  Grandmaster      0  15719\n",
       "13  Grandmaster      1   8702\n",
       "14  Grandmaster      2  25620\n",
       "15  Grandmaster      3   5697\n",
       "16  Grandmaster      4  16617\n",
       "17  Grandmaster      5   5073\n",
       "18       Master      0   5720\n",
       "19       Master      1   3129\n",
       "20       Master      2   9401\n",
       "21       Master      3   2069\n",
       "22       Master      4   5882\n",
       "23       Master      5   1852\n",
       "24       Novice      0  25516\n",
       "25       Novice      1  14245\n",
       "26       Novice      2  42079\n",
       "27       Novice      3   9452\n",
       "28       Novice      4  27061\n",
       "29       Novice      5   8230"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby(['ord_1','ord_2'])['id'].count().reset_index(name='count')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67da6fae-84eb-4e94-bb87-2818fa4d418c",
   "metadata": {},
   "source": [
    "- is used to count the number of rows (based on id) for each combination of ord_1 and ord_2 values in your DataFrame.\n",
    "- .reset_index(name=\"count\")\n",
    "Resets the index (so you get a flat DataFrame) and renames the id count column to \"count\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f839d48f-1a14-4fc8-a7b0-e629fafeb872",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    Grandmaster_1\n",
       "1    Grandmaster_3\n",
       "2         Expert_4\n",
       "3    Grandmaster_0\n",
       "4    Grandmaster_2\n",
       "Name: new feature, dtype: object"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create new feature\n",
    "df['new feature']=df.ord_1.astype(str)+\"_\"+df.ord_2.astype(str)\n",
    "df['new feature'].head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75445650-e05e-4761-a88f-29c8aad21fb5",
   "metadata": {},
   "source": [
    "#### Steps\n",
    "Whenever you get categorical variables, follow these simple steps:\n",
    "- • fill the NaN values (this is very important!)\n",
    "- • convert them to integers by applying label encoding using LabelEncoder of scikit-learn or by using a mapping dictionary. If you didn’t fill up NaN\n",
    "values with something, you might have to take care of them in this step\n",
    "- • create one-hot encoding. Yes, you can skip binarization!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cc7638b-395c-4576-8372-8f8795f79198",
   "metadata": {},
   "source": [
    "#### \"rare\" Category\n",
    "- A rare category is a category\n",
    "which is not seen very often and can include many different categories. You can\n",
    "also try to “predict” the unknown category by using a nearest neighbour model\n",
    "- if you predict this category, it will become one of the categories from\n",
    "the training data.\n",
    "- we can build a simple model\n",
    "that’s trained on all features except “f3”(feature column where rare value is there). Thus, you will be creating a model that\n",
    "predicts “f3” when it’s not known or not available in training."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "255b6672-19cc-4d53-9d6b-e4fbb7362f9b",
   "metadata": {},
   "source": [
    "🧠 If you design your cross-validation in such a way that it\n",
    "replicates the prediction process when you run your model on test data, then it’s\n",
    "never going to overfit."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16b11df6-5a85-4bdf-bcb0-57e0d1d8626c",
   "metadata": {},
   "source": [
    "for e.g 💡 Suppose you want to concatenate training and test data, then in each\n",
    "fold you must concatenate training and validation data and also make sure that your\n",
    "validation dataset replicates the test set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "336a769b-4591-4682-bdbe-de250f86168d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "# read training data\n",
    "train =pd.read_csv('/Users/akhichoudhary/STATS/Thinkstats/Thinkstats2_exercise/Thinkstats/Approach any problem with ml/data/train.csv')\n",
    "#read test data\n",
    "test =pd.read_csv('/Users/akhichoudhary/STATS/Thinkstats/Thinkstats2_exercise/Thinkstats/Approach any problem with ml/data/test.csv')\n",
    "# create a fake target column for test data\n",
    "# since this column doesn't exist\n",
    "test.loc[:, \"target\"] = -1\n",
    "# concatenate both training and test data\n",
    "data = pd.concat([train, test]).reset_index(drop=True)\n",
    "# make a list of features we are interested in\n",
    "# id and target is something we should not encode\n",
    "features = [x for x in train.columns if x not in [\"id\", \"target\"]]\n",
    "# loop over the features list\n",
    "for feat in features:\n",
    "    # create a new instance of LabelEncoder for each feature\n",
    "    lbl_enc = preprocessing.LabelEncoder()\n",
    "    # note the trick here\n",
    "    # since its categorical data, we fillna with a string\n",
    "    # and we convert all the data to string type\n",
    "    # so, no matter its int or float, its converted to string\n",
    "    # int/float but categorical!!!\n",
    "    temp_col = data[feat].fillna(\"NONE\").astype(str).values\n",
    "    # we can use fit_transform here as we do not\n",
    "    # have any extra test data that we need to\n",
    "    # transform on separately\n",
    "    data.loc[:, feat] = lbl_enc.fit_transform(temp_col)\n",
    "    # split the training and test data again\n",
    "train = data[data.target != -1].reset_index(drop=True)\n",
    "test = data[data.target == -1].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "05530c5b-ecaa-4675-ab3f-48940890243e",
   "metadata": {},
   "source": [
    "This trick works when you have a problem where you already have the test dataset.\n",
    "It must be noted that this trick will not work in a live setting. For example, let’s say\n",
    "you are in a company that builds a real-time bidding solution (RTB). RTB systems\n",
    "bid on every user they see online to buy ad space. The features that can be used for\n",
    "such a model may include pages viewed in a website\n",
    "A situation like this can be avoided by using an\n",
    "“unknown” category.`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "56ec4f24-d023-4880-a9c8-c864aa89e0e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ord_2\n",
       "Freezing       99816\n",
       "Lava Hot       63908\n",
       "Boiling Hot    60627\n",
       "Cold           33768\n",
       "Hot            22227\n",
       "Warm           19654\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df =pd.read_csv('/Users/akhichoudhary/STATS/Thinkstats/Thinkstats2_exercise/Thinkstats/Approach any problem with ml/data/train.csv')\n",
    "\n",
    "df.ord_2.fillna(\"NONE\").value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c182ccfa-878f-4923-be45-950c316ca5a9",
   "metadata": {},
   "source": [
    "- 🧠💡 We can treat “NONE” as unknown. So, if during live testing, we get new categories\n",
    "that we have not seen before, we will mark them as “NONE”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "c58c2d36-a264-4620-bbd5-b71c9524db5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "300000"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "b0cb6d2d-672e-46e0-9334-32d8cc205644",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ord_4\n",
       "L    19066\n",
       "G    18899\n",
       "S    18875\n",
       "A    18258\n",
       "R    16927\n",
       "Q    15925\n",
       "K    14698\n",
       "I    14644\n",
       "Z    14232\n",
       "T    14220\n",
       "V    14143\n",
       "J    12878\n",
       "P    12839\n",
       "U    12775\n",
       "H    12743\n",
       "F    11717\n",
       "E    11303\n",
       "W     9197\n",
       "Y     8490\n",
       "X     6292\n",
       "B     6169\n",
       "O     5836\n",
       "D     3974\n",
       "C     3575\n",
       "N     2166\n",
       "M      159\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.ord_4.fillna(\"NONE\").value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a1b4aac-0f93-4144-8508-ad33489f7288",
   "metadata": {},
   "source": [
    "- We see that some values appear only a couple thousand times, and some appear\n",
    "almost 40000 times.\n",
    "- define our criteria for calling a value “rare”. Let’s say the requirement\n",
    "for a value being rare in this column is a count of less than 3000\n",
    "- and all missing values will be mapped to\n",
    "“NONE”.(in data set not preset but in other case)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "56f043d6-a5a7-4715-82ff-8e15b9aca5d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df.ord_4.value_counts()[df.ord_4].values<3000,'ord_4']=\"RARE\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "302c90af-f915-4499-a1a9-d88cdcd8a751",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ord_4\n",
       "L       19066\n",
       "G       18899\n",
       "S       18875\n",
       "A       18258\n",
       "R       16927\n",
       "Q       15925\n",
       "K       14698\n",
       "I       14644\n",
       "Z       14232\n",
       "T       14220\n",
       "V       14143\n",
       "J       12878\n",
       "P       12839\n",
       "U       12775\n",
       "H       12743\n",
       "F       11717\n",
       "E       11303\n",
       "W        9197\n",
       "Y        8490\n",
       "X        6292\n",
       "B        6169\n",
       "O        5836\n",
       "D        3974\n",
       "C        3575\n",
       "RARE     2325\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.ord_4.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fac3f8e-eb94-4331-adb9-3c1f2caa1ca5",
   "metadata": {},
   "source": [
    "### Building our model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdfde235-49c4-42e2-b800-d80a07781fc4",
   "metadata": {},
   "source": [
    "Before going to any kind of model building, it’s essential to take care of cross-\n",
    "validation. We have already seen the label/target distribution, and we know that it\n",
    "is a binary classification problem with skewed targets. Thus, we will be using\n",
    "StratifiedKFold to split the data here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07967ceb-ee23-4fed-b407-c153fa91280b",
   "metadata": {},
   "source": [
    "#### Creat_folds for cat-in-data"
   ]
  },
  {
   "cell_type": "raw",
   "id": "22734ae7-dc6d-4e6f-9ceb-42896f6c2d4c",
   "metadata": {},
   "source": [
    "# create_folds.py\n",
    "# import pandas and model_selection module of scikit-learn\n",
    "\n",
    "import pandas as pd\n",
    "from skelean import model_selection\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn import model_selection\n",
    "if __name__ == \"__main__\":\n",
    "    # Read training data\n",
    "    df = pd.read_csv(\"/Users/akhichoudhary/STATS/Thinkstats/Thinkstats2_exercise/Thinkstats/Approach any problem with ml/mnist_classifier/input/cat-in-data/train.csv\")\n",
    "    # we create a new column called kfold and fill it with -1\n",
    "    df[\"kfold\"] = -1\n",
    "    # the next step is to randomize the rows of the data\n",
    "    df = df.sample(frac=1).reset_index(drop=True)\n",
    "    # fetch labels\n",
    "    y = df.target.values\n",
    "    # initiate the kfold class from model_selection module\n",
    "    kf = model_selection.StratifiedKFold(n_splits=5)\n",
    "    # fill the new kfold column\n",
    "    for f, (t_, v_) in enumerate(kf.split(X=df, y=y)):\n",
    "        df.loc[v_, 'kfold'] = f\n",
    "    # save the new csv with kfold column\n",
    "    df.to_csv('input/cat-in-data/cat_train_folds.csv')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7ff68b8-1f69-401b-9cb9-9a84f861e426",
   "metadata": {},
   "source": [
    "## Model-1 Logistic Regression + one Hot Encoding"
   ]
  },
  {
   "cell_type": "raw",
   "id": "83788e88-2469-46dd-8a52-c54c819b0a10",
   "metadata": {},
   "source": [
    "#ohe_logres.py\n",
    "import pandas as pd\n",
    "from sklearn import linear_model\n",
    "from sklearn import metrics\n",
    "from sklearn import preprocessing\n",
    "def run(fold):\n",
    "    # load the full training data with folds\n",
    "    df = pd.read_csv(\"input/cat-in-data/cat_train_folds.csv\")\n",
    "    # all columns are features except id, target and kfold columns\n",
    "    features = [\n",
    "    f for f in df.columns if f not in (\"id\", \"target\", \"kfold\")\n",
    "    ]\n",
    "    # fill all NaN values with NONE\n",
    "    # note that I am converting all columns to \"strings\"\n",
    "    # it doesn’t matter because all are categories\n",
    "    for col in features:\n",
    "        df.loc[:, col] = df[col].astype(str).fillna(\"NONE\")\n",
    "    # get training data using folds\n",
    "    df_train = df[df.kfold != fold].reset_index(drop=True)\n",
    "    # get validation data using folds\n",
    "    df_valid = df[df.kfold == fold].reset_index(drop=True)\n",
    "    # initialize OneHotEncoder from scikit-learn\n",
    "    ohe = preprocessing.OneHotEncoder()\n",
    "    # fit ohe on training + validation features\n",
    "    full_data = pd.concat(\n",
    "    [df_train[features], df_valid[features]],\n",
    "    axis=0\n",
    "    )\n",
    "    ohe.fit(full_data[features])\n",
    "    # transform training data\n",
    "    x_train = ohe.transform(df_train[features])\n",
    "    # transform validation data\n",
    "    x_valid = ohe.transform(df_valid[features])\n",
    "    # initialize Logistic Regression model\n",
    "    model = linear_model.LogisticRegression()\n",
    "    # fit model on training data (ohe)\n",
    "    model.fit(x_train, df_train.target.values)\n",
    "    # predict on validation data\n",
    "    # we need the probability values as we are calculating AUC\n",
    "    # we will use the probability of 1s\n",
    "    valid_preds = model.predict_proba(x_valid)[:, 1]\n",
    "    # get roc auc score\n",
    "    auc = metrics.roc_auc_score(df_valid.target.values, valid_preds)\n",
    "    # print auc\n",
    "    print(auc)\n",
    "if __name__ == \"__main__\":\n",
    "# run function for fold = 0\n",
    "# we can just replace this number and\n",
    "# run this for any fold\n",
    "    run(0)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "821a017b-4d29-464c-8dab-cd804582dd33",
   "metadata": {},
   "source": [
    "❯ python -W ignore ohe_logres.py\n",
    "we can error below error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9282486d-2ac5-4806-bdf3-1ca1d79ccd86",
   "metadata": {},
   "source": [
    "/Users/akhichoudhary/STATS/Thinkstats/Thinkstats2_exercise/Thinkstats/Approach any problem with ml/mnist_classifier/src/ohe_logres.py:17: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '['0' '1' '2' ... '299997' '299998' '299999']' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
    "  df.loc[:, col] = df[col].astype(str).fillna(\"NONE\")\n",
    "/Users/akhichoudhary/STATS/Thinkstats/Thinkstats2_exercise/Thinkstats/Approach any problem with ml/mnist_classifier/src/ohe_logres.py:17: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '['0' '0' '0' ... '0' '0' '0']' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
    "  df.loc[:, col] = df[col].astype(str).fillna(\"NONE\")\n",
    "/Users/akhichoudhary/STATS/Thinkstats/Thinkstats2_exercise/Thinkstats/Approach any problem with ml/mnist_classifier/src/ohe_logres.py:17: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '['0' '0' '0' ... '0' '0' '1']' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
    "  df.loc[:, col] = df[col].astype(str).fillna(\"NONE\")\n",
    "/Users/akhichoudhary/STATS/Thinkstats/Thinkstats2_exercise/Thinkstats/Approach any problem with ml/mnist_classifier/src/ohe_logres.py:17: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '['0' '0' '1' ... '0' '0' '0']' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
    "  df.loc[:, col] = df[col].astype(str).fillna(\"NONE\")\n",
    "/Users/akhichoudhary/STATS/Thinkstats/Thinkstats2_exercise/Thinkstats/Approach any problem with ml/mnist_classifier/src/ohe_logres.py:17: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '['1' '1' '3' ... '1' '1' '3']' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
    "  df.loc[:, col] = df[col].astype(str).fillna(\"NONE\")\n",
    "/Users/akhichoudhary/STATS/Thinkstats/Thinkstats2_exercise/Thinkstats/Approach any problem with ml/mnist_classifier/src/ohe_logres.py:17: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '['3' '1' '4' ... '1' '2' '5']' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
    "  df.loc[:, col] = df[col].astype(str).fillna(\"NONE\")\n",
    "/Users/akhichoudhary/STATS/Thinkstats/Thinkstats2_exercise/Thinkstats/Approach any problem with ml/mnist_classifier/src/ohe_logres.py:17: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '['3' '3' '4' ... '2' '3' '5']' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
    "  df.loc[:, col] = df[col].astype(str).fillna(\"NONE\")\n",
    "/Users/akhichoudhary/miniconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:470: ConvergenceWarning: lbfgs failed to converge after 100 iteration(s) (status=1):\n",
    "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
    "\n",
    "Increase the number of iterations to improve the convergence (max_iter=100).\n",
    "You might also want to scale the data as shown in:\n",
    "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
    "Please also refer to the documentation for alternative solver options:\n",
    "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
    "  n_iter_i = _check_optimize_result(\n",
    "-- $$ 0.7916089250181116 $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "e9e0acb0-d02e-456f-97c4-05a2cd23ecee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/akhichoudhary/STATS/Thinkstats/Thinkstats2_exercise/Thinkstats/Approach any problem with ml\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "raw",
   "id": "73ff0ee7-d20e-4e06-a7bd-95d9a0a973de",
   "metadata": {},
   "source": [
    "# as error states we have not used many parameters\n",
    "# ohe_logres.py\n",
    ".\n",
    ".\n",
    ".\n",
    "# initialize Logistic Regression model\n",
    "model = linear_model.LogisticRegression()\n",
    "# fit model on training data (ohe)\n",
    "model.fit(x_train, df_train.target.values)\n",
    "# predict on validation data\n",
    "# we need the probability values as we are calculating AUC\n",
    "# we will use the probability of 1s\n",
    "valid_preds = model.predict_proba(x_valid)[:, 1]\n",
    "# get roc auc score\n",
    "auc = metrics.roc_auc_score(df_valid.target.values, valid_preds)\n",
    "# print auc\n",
    "print(f\"Fold = {fold}, AUC = {auc}\")\n",
    "if __name__ == \"__main__\":\n",
    "for fold_ in range(5):\n",
    "run(fold_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "d73e174c-fcf1-4912-9dbf-21c843a6863b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # python -W ignore src/ohe_logres.py\n",
    "# Fold = 0, AUC = 0.7916089250181116\n",
    "# Fold = 1, AUC = 0.7885835002477297\n",
    "# Fold = 2, AUC = 0.7908998540691035\n",
    "# Fold = 3, AUC = 0.7898881988857341\n",
    "# Fold = 4, AUC = 0.7915466071107451"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7545d57-5683-4513-a5e5-f3812670e541",
   "metadata": {},
   "source": [
    "## Model -2 RandomForest + labelEncoder()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "0ea36a3f-50c2-4e6a-8668-4c3ac38c4b20",
   "metadata": {},
   "source": [
    "#lbl_rf.py\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn import ensemble\n",
    "from sklearn import metrics\n",
    "from sklearn import preprocessing\n",
    "def run(fold):\n",
    "# load the full training data with folds\n",
    "    df = pd.read_csv(\"input/cat-in-data/cat_train_folds.csv\")\n",
    "    # all columns are features except id, target and kfold columns\n",
    "    features = [\n",
    "    f for f in df.columns if f not in (\"id\", \"target\", \"kfold\")\n",
    "    ]\n",
    "    # fill all NaN values with NONE\n",
    "    # note that I am converting all columns to \"strings\"\n",
    "    # it doesnt matter because all are categories\n",
    "    for col in features:\n",
    "        df.loc[:, col] = df[col].astype(str).fillna(\"NONE\")\n",
    "    # now its time to label encode the features\n",
    "    for col in features:\n",
    "        # initialize LabelEncoder for each feature column\n",
    "        lbl = preprocessing.LabelEncoder()\n",
    "        # fit label encoder on all data\n",
    "        lbl.fit(df[col])\n",
    "        # transform all the data\n",
    "        df.loc[:, col] = lbl.transform(df[col])\n",
    "    # get training data using folds\n",
    "    df_train = df[df.kfold != fold].reset_index(drop=True)\n",
    "    # get validation data using folds\n",
    "    df_valid = df[df.kfold == fold].reset_index(drop=True)\n",
    "    # get training data\n",
    "    x_train = df_train[features].values\n",
    "    # get validation data\n",
    "    x_valid = df_valid[features].values\n",
    "    # initialize random forest model\n",
    "    model = ensemble.RandomForestClassifier(n_jobs=-1)\n",
    "    # fit model on training data (ohe)\n",
    "    model.fit(x_train, df_train.target.values)\n",
    "    # predict on validation data\n",
    "    # we need the probability values as we are calculating AUC\n",
    "    # we will use the probability of 1s\n",
    "    valid_preds = model.predict_proba(x_valid)[:, 1]\n",
    "    # get roc auc score\n",
    "    auc = metrics.roc_auc_score(df_valid.target.values, valid_preds)\n",
    "    # print auc\n",
    "    print(f\"Fold = {fold}, AUC = {auc}\")\n",
    "if __name__ == \"__main__\":\n",
    "    for fold_ in range(5):\n",
    "        run(fold_)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b26fb52a-0ecb-4fa6-8c2e-1ece2668f0a0",
   "metadata": {},
   "source": [
    "Fold = 0, AUC = 0.7343016790092144\n",
    "Fold = 1, AUC = 0.7287232926526728\n",
    "Fold = 2, AUC = 0.7363651385839556\n",
    "Fold = 3, AUC = 0.7361422288154315\n",
    "Fold = 4, AUC = 0.7334020232169537"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8acab45a-5930-4ba8-b6b9-6b8b4c1c0385",
   "metadata": {},
   "source": [
    "#### n_jobs=-1 →\n",
    "- Tells scikit-learn how many CPU cores to use in parallel when building the forest.\n",
    "#### n_jobs can be:\n",
    "- 1 → Use only one core (no parallelism).\n",
    "- -1 → Use all available cores on your machine.\n",
    "- Any positive integer → Use that many cores (e.g., n_jobs=4 uses 4 cores).\n",
    "#### Why use [:, 1]?\n",
    "- In binary classification, column index 0 is P(class=0) and column index 1 is P(class=1).\n",
    "  | Method            | Output                        | Use case                                                                      |\n",
    "| ----------------- | ----------------------------- | ----------------------------------------------------------------------------- |\n",
    "| `predict()`       | Class labels (0/1)            | When you just want the predicted category                                     |\n",
    "| `predict_proba()` | Probabilities for all classes | When you need probability scores for metrics like ROC AUC, log loss, PR curve |\n",
    "\n",
    "#### 1. model.predict(x_valid)\n",
    "- Returns: The predicted class label for each row (e.g., 0 or 1 in binary classification).\n",
    "\n",
    "- Uses the probabilities internally, but applies a decision threshold (default = 0.5).\n",
    "\n",
    "- Probs: [[0.80, 0.20],\n",
    "        [0.35, 0.65],\n",
    "        [0.10, 0.90]]\n",
    "\n",
    "- model.predict(...) → [0, 1, 1]\n",
    "\n",
    "\n",
    "\n",
    "#### 2. model.predict_proba(x_valid)\n",
    "- Returns: The probability distribution over all classes for each row.\n",
    "\n",
    "- Shape: (n_samples, n_classes).\n",
    "\n",
    "- model.predict_proba(...) →\n",
    "[[0.80, 0.20],\n",
    " [0.35, 0.65],\n",
    " [0.10, 0.90]]\n",
    "\n",
    "- [[0.80, 0.20],   # Sample 1 → 80% class 0, 20% class 1\n",
    "-  [0.35, 0.65],   # Sample 2 → 35% class 0, 65% class 1\n",
    "-  [0.10, 0.90]]   # Sample 3 → 10% class 0, 90% class 1\n",
    "\n",
    "- valid_preds = probability of target = 1 for each validation sample.\n",
    "\n",
    "### df_valid.target.values → Actual labels (0 or 1).\n",
    "\n",
    "valid_preds → Probability that each sample is class 1 (positive class).\n",
    "\n",
    "So if valid_preds[i] = 0.87, that means:\n",
    "\n",
    "“The model thinks there’s an 87% chance this sample is class 1.”\n",
    "\n",
    "How AUC uses this\n",
    "ROC AUC does not fix a single threshold (like 0.5).\n",
    "\n",
    "Instead, it:\n",
    "\n",
    "Sorts samples by predicted probability.\n",
    "\n",
    "Sweeps through all possible thresholds (0 → 1).\n",
    "\n",
    "Calculates True Positive Rate vs False Positive Rate for each threshold.\n",
    "\n",
    "The area under that curve = how well the model ranks positives above negatives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "50f9e714-f9d3-4952-8b73-4add28b07ce2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "# Example true labels and predicted probabilities\n",
    "y_true = [1, 0, 1, 0, 1, 0, 1, 0]\n",
    "y_scores = [0.95, 0.85, 0.70, 0.10, 0.80, 0.40, 0.65, 0.20]\n",
    "\n",
    "# Calculate ROC curve points\n",
    "fpr, tpr, thresholds = roc_curve(y_true, y_scores)\n",
    "\n",
    "# Calculate AUC\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "# Plot ROC curve\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.plot(fpr, tpr, color='blue', lw=2, label=f'ROC curve (AUC = {roc_auc:.2f})')\n",
    "plt.plot([0, 1], [0, 1], color='grey', lw=1, linestyle='--', label='Random Guess')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve Example')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "636682cc-c356-4289-8832-09360d02468b",
   "metadata": {},
   "source": [
    "Here’s the visual:\n",
    "\n",
    "Blue line → How the model’s performance changes as we vary the probability threshold from 1 → 0.\n",
    "\n",
    "Grey dashed line → Random guessing (AUC = 0.5).\n",
    "\n",
    "AUC value → The area under the blue curve; here it’s well above 0.5, meaning the model ranks positives above negatives quite well.\n",
    "\n",
    "The further the blue curve is toward the top-left corner, the better the model is at separating class 1 from class 0. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbdbdb89-db26-4105-8505-eb8c323c7ee7",
   "metadata": {},
   "source": [
    "## Model-3 Random Forest + One Hot encoding+Simple value decomposition(SVD)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "95e07b8e-9ea0-472a-a2cc-a273d26f7e45",
   "metadata": {},
   "source": [
    "# ohe_svd_rf.py\n",
    "import pandas as pd\n",
    "from scipy import sparse\n",
    "from sklearn import decomposition\n",
    "from sklearn import ensemble\n",
    "from sklearn import metrics\n",
    "from sklearn import preprocessing\n",
    "def run(fold):\n",
    "    # load the full training data with folds\n",
    "    df = pd.read_csv(\"input/cat-in-data/cat_train_folds.csv\")\n",
    "    # all columns are features except id, target and kfold columns\n",
    "    features = [\n",
    "    f for f in df.columns if f not in (\"id\", \"target\", \"kfold\")\n",
    "        ]\n",
    "    # fill all NaN values with NONE\n",
    "    # note that I am converting all columns to \"strings\"\n",
    "    # it doesnt matter because all are categories\n",
    "    for col in features:\n",
    "       df[col] = df[col].astype(str).fillna(\"NONE\").astype(\"string\")\n",
    "        # get training data using folds\n",
    "    df_train = df[df.kfold != fold].reset_index(drop=True)\n",
    "    # get validation data using folds\n",
    "    df_valid = df[df.kfold == fold].reset_index(drop=True)\n",
    "    # initialize OneHotEncoder from scikit-learn\n",
    "    ohe = preprocessing.OneHotEncoder()\n",
    "    # fit ohe on training + validation features\n",
    "    full_data = pd.concat(\n",
    "    [df_train[features], df_valid[features]],\n",
    "    axis=0\n",
    "    )\n",
    "    ohe.fit(full_data[features])\n",
    "    # transform training data\n",
    "    x_train = ohe.transform(df_train[features])\n",
    "    # transform validation data\n",
    "    x_valid = ohe.transform(df_valid[features])\n",
    "    # initialize Truncated SVD\n",
    "    # we are reducing the data to 120 components\n",
    "    svd = decomposition.TruncatedSVD(n_components=120)\n",
    "    # fit svd on full sparse training data\n",
    "    full_sparse = sparse.vstack((x_train, x_valid))\n",
    "    svd.fit(full_sparse)\n",
    "    # transform sparse training data\n",
    "    x_train = svd.transform(x_train)\n",
    "    # transform sparse validation data\n",
    "    x_valid = svd.transform(x_valid)\n",
    "    # initialize random forest model\n",
    "    model = ensemble.RandomForestClassifier(n_jobs=-1)\n",
    "    # fit model on training data (ohe)\n",
    "    model.fit(x_train, df_train.target.values)\n",
    "    # predict on validation data\n",
    "    # we need the probability values as we are calculating AUC\n",
    "    # we will use the probability of 1s\n",
    "    valid_preds = model.predict_proba(x_valid)[:, 1]\n",
    "    # get roc auc score\n",
    "    auc = metrics.roc_auc_score(df_valid.target.values, valid_preds)\n",
    "    # print auc\n",
    "    print(f\"Fold = {fold}, AUC = {auc}\")\n",
    "if __name__ == \"__main__\":\n",
    "    for fold_ in range(5):\n",
    "        run(fold_)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "e37f8710-3224-4b8d-87e3-06fe9fb2cf84",
   "metadata": {},
   "source": [
    "# python  src/ohe_svd_rf.py\n",
    "Fold = 0, AUC = 0.7101843940819575\n",
    "Fold = 1, AUC = 0.7167653333430427\n",
    "Fold = 2, AUC = 0.7151233338873266\n",
    "Fold = 3, AUC = 0.7165376835831968\n",
    "Fold = 4, AUC = 0.7096388453558546"
   ]
  },
  {
   "cell_type": "raw",
   "id": "1de37c08-8088-4388-9d7a-95d528814cbf",
   "metadata": {},
   "source": [
    "We see that it is even worse. It seems like the best method for this problem is one-\n",
    "hot encoding with logistic regression. Random forest appears to be taking way too\n",
    "much time."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2e19e91-4d77-4e07-8134-975214d0fd9f",
   "metadata": {},
   "source": [
    "## Model-4 XGBoost+LabelEncoder"
   ]
  },
  {
   "cell_type": "raw",
   "id": "4253361b-82e7-4c0f-968c-dfd441714df2",
   "metadata": {},
   "source": [
    "#lbl_xgb.py\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "from sklearn import metrics\n",
    "from sklearn import preprocessing\n",
    "\n",
    "def run(fold):\n",
    "    # load the full training data with folds\n",
    "    df = pd.read_csv(\"input/cat-in-data/cat_train_folds.csv\")\n",
    "    # all columns are features except id, target and kfold columns\n",
    "    features = [\n",
    "    f for f in df.columns if f not in (\"id\", \"target\", \"kfold\")\n",
    "    ]\n",
    "    # fill all NaN values with NONE\n",
    "    # note that I am converting all columns to \"strings\"\n",
    "    # it doesnt matter because all are categories\n",
    "    for col in features:\n",
    "        df.loc[:, col] = df[col].astype(str).fillna(\"NONE\")\n",
    "        # now it’s time to label encode the features\n",
    "    for col in features:\n",
    "        # initialize LabelEncoder for each feature column\n",
    "        lbl = preprocessing.LabelEncoder()\n",
    "        # fit label encoder on all data\n",
    "        lbl.fit(df[col])\n",
    "        # transform all the data\n",
    "        df.loc[:, col] = lbl.transform(df[col])\n",
    "        # get training data using folds\n",
    "    df_train = df[df.kfold != fold].reset_index(drop=True)\n",
    "    # get validation data using folds\n",
    "    df_valid = df[df.kfold == fold].reset_index(drop=True)\n",
    "    # get training data\n",
    "    x_train = df_train[features].values\n",
    "    # get validation data\n",
    "    x_valid = df_valid[features].values\n",
    "    # initialize xgboost model\n",
    "    model = xgb.XGBClassifier(\n",
    "        n_jobs=-1,\n",
    "        max_depth=7,\n",
    "        n_estimators=200\n",
    "        )\n",
    "    # fit model on training data (ohe)\n",
    "    model.fit(x_train, df_train.target.values)\n",
    "    # predict on validation data\n",
    "    # we need the probability values as we are calculating AUC\n",
    "    # we will use the probability of 1s\n",
    "    valid_preds = model.predict_proba(x_valid)[:, 1]\n",
    "    # get roc auc score\n",
    "    auc = metrics.roc_auc_score(df_valid.target.values, valid_preds)\n",
    "    # print auc\n",
    "    print(f\"Fold = {fold}, AUC = {auc}\")\n",
    "if __name__ == \"__main__\":\n",
    "    for fold_ in range(5):\n",
    "        run(fold_)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "be446d39-278f-4c21-b406-9d9948004cfc",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# python -W ignore  src/lbl_xgb.py\n",
    "Fold = 0, AUC = 0.7454949143720311\n",
    "Fold = 1, AUC = 0.7399454765719218\n",
    "Fold = 2, AUC = 0.7503724095265474\n",
    "Fold = 3, AUC = 0.7557724338461175\n",
    "Fold = 4, AUC = 0.7595082875085002"
   ]
  },
  {
   "cell_type": "raw",
   "id": "72a7cba8-f4b6-4858-a256-9277452a8105",
   "metadata": {},
   "source": [
    "We see that we have much better scores than plain random forest without any tuning\n",
    "and we can probably improve this further with more tuning of hyperparameters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0b790da-c033-44ec-98e6-5fdbe0d65787",
   "metadata": {},
   "source": [
    "## Adult data frame \n",
    "#### - ohe_logres.py\n",
    "#### - lbl_xgb.py\n",
    "#### - lbl_xgb_num.py\n",
    "#### - lbl_xgb_num_feat.py\n",
    "#### - target_encoding.py\n",
    "#### - entity_embeddings.py - for cat-in-data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "30883582-cb04-4b84-8267-5c17127b321f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded rows: 32561\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 32561 entries, 0 to 32560\n",
      "Data columns (total 15 columns):\n",
      " #   Column          Non-Null Count  Dtype \n",
      "---  ------          --------------  ----- \n",
      " 0   age             32561 non-null  int64 \n",
      " 1   workclass       32561 non-null  object\n",
      " 2   fnlwgt          32561 non-null  int64 \n",
      " 3   education       32561 non-null  object\n",
      " 4   education_num   32561 non-null  int64 \n",
      " 5   marital_status  32561 non-null  object\n",
      " 6   occupation      32561 non-null  object\n",
      " 7   relationship    32561 non-null  object\n",
      " 8   race            32561 non-null  object\n",
      " 9   sex             32561 non-null  object\n",
      " 10  capital_gain    32561 non-null  int64 \n",
      " 11  capital_loss    32561 non-null  int64 \n",
      " 12  hours_per_week  32561 non-null  int64 \n",
      " 13  native_country  32561 non-null  object\n",
      " 14  income          32561 non-null  object\n",
      "dtypes: int64(6), object(9)\n",
      "memory usage: 3.7+ MB\n"
     ]
    }
   ],
   "source": [
    "# pd.read_csv('https://archive.ics.uci.edu/ml/datasets/adult.csv')\n",
    "import pandas as pd\n",
    "\n",
    "column_names = [\n",
    "    \"age\", \"workclass\", \"fnlwgt\", \"education\", \"education_num\",\n",
    "    \"marital_status\", \"occupation\", \"relationship\", \"race\", \"sex\",\n",
    "    \"capital_gain\", \"capital_loss\", \"hours_per_week\", \"native_country\", \"income\"\n",
    "]\n",
    "\n",
    "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.data\"\n",
    "\n",
    "df = pd.read_csv(\n",
    "    url,\n",
    "    header=None,\n",
    "    names=column_names,\n",
    "    sep=',\\s*',\n",
    "    engine='python'\n",
    ")\n",
    "\n",
    "print(\"Loaded rows:\", df.shape[0])\n",
    "df.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "d65df4fc-c39a-4930-b21f-1663a9973f1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "income\n",
       "<=50K    24720\n",
       ">50K      7841\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.income.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "d51709de-44f5-4e3b-9795-55bd3fcc82ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>education_num</th>\n",
       "      <th>marital_status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital_gain</th>\n",
       "      <th>capital_loss</th>\n",
       "      <th>hours_per_week</th>\n",
       "      <th>native_country</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>State-gov</td>\n",
       "      <td>77516</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>2174</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>83311</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>215646</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age         workclass  fnlwgt  education  education_num  \\\n",
       "0   39         State-gov   77516  Bachelors             13   \n",
       "1   50  Self-emp-not-inc   83311  Bachelors             13   \n",
       "2   38           Private  215646    HS-grad              9   \n",
       "\n",
       "       marital_status         occupation   relationship   race   sex  \\\n",
       "0       Never-married       Adm-clerical  Not-in-family  White  Male   \n",
       "1  Married-civ-spouse    Exec-managerial        Husband  White  Male   \n",
       "2            Divorced  Handlers-cleaners  Not-in-family  White  Male   \n",
       "\n",
       "   capital_gain  capital_loss  hours_per_week native_country income  \n",
       "0          2174             0              40  United-States  <=50K  \n",
       "1             0             0              13  United-States  <=50K  \n",
       "2             0             0              40  United-States  <=50K  "
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4edf8579-18ef-438a-8574-940b2548d6b5",
   "metadata": {},
   "source": [
    "### 1 ohe_logres.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "11fa9e7e-365c-4ed4-adca-0fe25ddfaf76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold=0, AUC=0.8752\n",
      "Fold=1, AUC=0.8823\n",
      "Fold=2, AUC=0.8766\n",
      "Fold=3, AUC=0.8784\n",
      "Fold=4, AUC=0.8804\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "from sklearn import linear_model\n",
    "from sklearn import metrics\n",
    "from sklearn import preprocessing\n",
    "\n",
    "def run(fold):\n",
    "    # load the full training data with folds\n",
    "    df = pd.read_csv(\"/Users/akhichoudhary/STATS/Thinkstats/Thinkstats2_exercise/Thinkstats/Approach any problem with ml/mnist_classifier/input/adult_folds.csv\")\n",
    "    # list of numerical columns\n",
    "        # list of numerical columns\n",
    "    num_cols = [\n",
    "    \"fnlwgt\",\n",
    "    \"age\",\n",
    "    \"capital_gain\",\n",
    "    \"capital_loss\",\n",
    "    \"hours_per_week\"\n",
    "    ]\n",
    "    # drop numerical columns\n",
    "    df = df.drop(num_cols, axis=1)\n",
    "    features = [c for c in df.columns if c not in (\"kfold\", \"income\")]\n",
    "\n",
    "    # clean income column first\n",
    "    df[\"income\"] = df[\"income\"].str.strip()\n",
    "    \n",
    "    # map targets\n",
    "    target_mapping = {\"<=50K\": 0, \">50K\": 1}\n",
    "    df[\"income\"] = df[\"income\"].map(target_mapping)\n",
    "    \n",
    "    # get training and validation\n",
    "    df_train = df[df.kfold != fold].reset_index(drop=True)\n",
    "    df_valid = df[df.kfold == fold].reset_index(drop=True)\n",
    "    \n",
    "    # OneHotEncoder\n",
    "    ohe = preprocessing.OneHotEncoder(handle_unknown=\"ignore\")\n",
    "    \n",
    "    # fit only on training\n",
    "    ohe.fit(df_train[features])\n",
    "    \n",
    "    # transform\n",
    "    x_train = ohe.transform(df_train[features])\n",
    "    x_valid = ohe.transform(df_valid[features])\n",
    "    \n",
    "    # model\n",
    "    model = linear_model.LogisticRegression(max_iter=1000, solver=\"liblinear\")\n",
    "    model.fit(x_train, df_train.income.values)\n",
    "    \n",
    "    # predict\n",
    "    valid_preds = model.predict_proba(x_valid)[:, 1]\n",
    "    auc = metrics.roc_auc_score(df_valid.income.values, valid_preds)\n",
    "    print(f\"Fold={fold}, AUC={auc:.4f}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    for fold_ in range(5):\n",
    "        run(fold_)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "26f98828-754b-444c-ab32-d5f76c711ac2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        <=50K\n",
       "1        <=50K\n",
       "2        <=50K\n",
       "3        <=50K\n",
       "4        <=50K\n",
       "         ...  \n",
       "32556    <=50K\n",
       "32557     >50K\n",
       "32558    <=50K\n",
       "32559    <=50K\n",
       "32560     >50K\n",
       "Name: income, Length: 32561, dtype: object"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.income"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "378bf973-21c2-4e17-a2b9-e867a63612df",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_mapping = {\n",
    "    \"<=50K\": 0,\n",
    "    \">50K\": 1\n",
    "    }\n",
    "df.loc[:, \"income\"] = df.income.map(target_mapping)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "e240d688-0c32-4d2d-bcce-16753d7b737d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        0\n",
       "1        0\n",
       "2        0\n",
       "3        0\n",
       "4        0\n",
       "        ..\n",
       "32556    0\n",
       "32557    1\n",
       "32558    0\n",
       "32559    0\n",
       "32560    1\n",
       "Name: income, Length: 32561, dtype: object"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.income"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "2d4dc539-45e6-4e12-bb80-de72f0fc9360",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/akhichoudhary/STATS/Thinkstats/Thinkstats2_exercise/Thinkstats/Approach any problem with ml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "python(64468) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8847bf90-5381-46af-a474-769346f2e526",
   "metadata": {},
   "source": [
    "### 2.lbl_xgb.py "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "e0fc8eac-2db5-40e2-91d7-076d11be0821",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/12/psznqclx2xgg8vrwnyfm9r6h0000gn/T/ipykernel_3817/2921746505.py:35: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '['4' '5' '9' ... '6' '10' '10']' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  df.loc[:, col] = df[col].astype(str).fillna(\"NONE\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold = 0, AUC = 0.8690944699177635\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/12/psznqclx2xgg8vrwnyfm9r6h0000gn/T/ipykernel_3817/2921746505.py:35: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '['4' '5' '9' ... '6' '10' '10']' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  df.loc[:, col] = df[col].astype(str).fillna(\"NONE\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold = 1, AUC = 0.8800220634370253\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/12/psznqclx2xgg8vrwnyfm9r6h0000gn/T/ipykernel_3817/2921746505.py:35: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '['4' '5' '9' ... '6' '10' '10']' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  df.loc[:, col] = df[col].astype(str).fillna(\"NONE\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold = 2, AUC = 0.8733100263770557\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/12/psznqclx2xgg8vrwnyfm9r6h0000gn/T/ipykernel_3817/2921746505.py:35: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '['4' '5' '9' ... '6' '10' '10']' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  df.loc[:, col] = df[col].astype(str).fillna(\"NONE\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold = 3, AUC = 0.873416512387722\n",
      "Fold = 4, AUC = 0.8768071017848887\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/12/psznqclx2xgg8vrwnyfm9r6h0000gn/T/ipykernel_3817/2921746505.py:35: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '['4' '5' '9' ... '6' '10' '10']' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  df.loc[:, col] = df[col].astype(str).fillna(\"NONE\")\n"
     ]
    }
   ],
   "source": [
    "# lbl_xgb_num.py\n",
    "# Now, let’s try to include numerical features in the xgboost model without parameter tuning.\n",
    "# =================== adult dataset=============================================\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "from sklearn import metrics\n",
    "from sklearn import preprocessing\n",
    "def run(fold):\n",
    "    # load the full training data with folds\n",
    "    df = pd.read_csv(\"/Users/akhichoudhary/STATS/Thinkstats/Thinkstats2_exercise/Thinkstats/Approach any problem with ml/mnist_classifier/input/adult_folds.csv\")\n",
    "    # list of numerical columns\n",
    "    num_cols = [\n",
    "    \"fnlwgt\",\n",
    "    \"age\",\n",
    "    \"capital_gain\",\n",
    "    \"capital_loss\",\n",
    "    \"hours_per_week\"\n",
    "    ]\n",
    "    # drop numerical columns\n",
    "    df = df.drop(num_cols, axis=1)\n",
    "    # map targets to 0s and 1s\n",
    "    target_mapping = {\n",
    "    \"<=50K\": 0,\n",
    "    \">50K\": 1\n",
    "    }\n",
    "    df.loc[:, \"income\"] = df.income.str.strip().map(target_mapping)\n",
    "    # all columns are features except kfold & income columns\n",
    "    features = [\n",
    "    f for f in df.columns if f not in (\"kfold\", \"income\")\n",
    "    ]\n",
    "    # fill all NaN values with NONE\n",
    "    # note that I am converting all columns to \"strings\"\n",
    "    # it doesnt matter because all are categories\n",
    "    for col in features:\n",
    "        df.loc[:, col] = df[col].astype(str).fillna(\"NONE\")\n",
    "    # now its time to label encode the features\n",
    "    for col in features:\n",
    "        # initialize LabelEncoder for each feature column\n",
    "        lbl = preprocessing.LabelEncoder()\n",
    "        # fit label encoder on all data\n",
    "        lbl.fit(df[col])\n",
    "        # transform all the data\n",
    "        df.loc[:, col] = lbl.transform(df[col])\n",
    "    # get training data using folds\n",
    "    df_train = df[df.kfold != fold].reset_index(drop=True)\n",
    "    # get validation data using folds\n",
    "    df_valid = df[df.kfold == fold].reset_index(drop=True)\n",
    "    # get training data\n",
    "    x_train = df_train[features].values\n",
    "    # get validation data\n",
    "    x_valid = df_valid[features].values\n",
    "    # initialize xgboost model\n",
    "    model = xgb.XGBClassifier(\n",
    "    n_jobs=-1\n",
    "    )\n",
    "    # fit model on training data (ohe)\n",
    "    model.fit(x_train, df_train.income.values)\n",
    "    # predict on validation data\n",
    "    # we need the probability values as we are calculating AUC\n",
    "    # we will use the probability of 1s\n",
    "    valid_preds = model.predict_proba(x_valid)[:, 1]\n",
    "    # get roc auc score\n",
    "    auc = metrics.roc_auc_score(df_valid.income.astype(int).values, valid_preds)\n",
    "    # print auc\n",
    "    print(f\"Fold = {fold}, AUC = {auc}\")\n",
    "if __name__ == \"__main__\":\n",
    "    for fold_ in range(5):\n",
    "        run(fold_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dde9204f-25b9-4c44-afa9-14b68a0798a7",
   "metadata": {},
   "source": [
    "### 3 lbl_xgb_num.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "42e0eb35-24ac-4fcf-af1a-feb3e8f41f3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/12/psznqclx2xgg8vrwnyfm9r6h0000gn/T/ipykernel_3817/2413094749.py:32: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '['4' '5' '9' ... '6' '10' '10']' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  df.loc[:, col] = df[col].astype(str).fillna(\"NONE\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold = 0, AUC = 0.9205525080390493\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/12/psznqclx2xgg8vrwnyfm9r6h0000gn/T/ipykernel_3817/2413094749.py:32: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '['4' '5' '9' ... '6' '10' '10']' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  df.loc[:, col] = df[col].astype(str).fillna(\"NONE\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold = 1, AUC = 0.9303020358628887\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/12/psznqclx2xgg8vrwnyfm9r6h0000gn/T/ipykernel_3817/2413094749.py:32: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '['4' '5' '9' ... '6' '10' '10']' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  df.loc[:, col] = df[col].astype(str).fillna(\"NONE\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold = 2, AUC = 0.9257031430594083\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/12/psznqclx2xgg8vrwnyfm9r6h0000gn/T/ipykernel_3817/2413094749.py:32: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '['4' '5' '9' ... '6' '10' '10']' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  df.loc[:, col] = df[col].astype(str).fillna(\"NONE\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold = 3, AUC = 0.927766430449607\n",
      "Fold = 4, AUC = 0.9238521182137905\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/12/psznqclx2xgg8vrwnyfm9r6h0000gn/T/ipykernel_3817/2413094749.py:32: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '['4' '5' '9' ... '6' '10' '10']' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  df.loc[:, col] = df[col].astype(str).fillna(\"NONE\")\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "from sklearn import metrics\n",
    "from sklearn import preprocessing\n",
    "def run(fold):\n",
    "    # load the full training data with folds\n",
    "    df = pd.read_csv(\"/Users/akhichoudhary/STATS/Thinkstats/Thinkstats2_exercise/Thinkstats/Approach any problem with ml/mnist_classifier/input/adult_folds.csv\")\n",
    "    # list of numerical columns\n",
    "    num_cols = [\n",
    "    \"fnlwgt\",\n",
    "    \"age\",\n",
    "    \"capital_gain\",\n",
    "    \"capital_loss\",\n",
    "    \"hours_per_week\"\n",
    "    ]\n",
    "    # map targets to 0s and 1s\n",
    "    target_mapping = {\n",
    "    \"<=50K\": 0,\n",
    "    \">50K\": 1\n",
    "    }\n",
    "    df.loc[:, \"income\"] = df.income.map(target_mapping)\n",
    "    # all columns are features except kfold & income columns\n",
    "    features = [\n",
    "    f for f in df.columns if f not in (\"kfold\", \"income\")\n",
    "    ]\n",
    "    # fill all NaN values with NONE\n",
    "    # note that I am converting all columns to \"strings\"\n",
    "    # it doesnt matter because all are categories\n",
    "    for col in features:\n",
    "    # do not encode the numerical columns\n",
    "        if col not in num_cols:\n",
    "            df.loc[:, col] = df[col].astype(str).fillna(\"NONE\")\n",
    "    # now its time to label encode the features\n",
    "    for col in features:\n",
    "        if col not in num_cols:\n",
    "    # initialize LabelEncoder for each feature column\n",
    "            lbl = preprocessing.LabelEncoder()\n",
    "    # fit label encoder on all data\n",
    "            lbl.fit(df[col])\n",
    "    # transform all the data\n",
    "            df.loc[:, col] = lbl.transform(df[col])\n",
    "    # get training data using folds\n",
    "    df_train = df[df.kfold != fold].reset_index(drop=True)\n",
    "    # get validation data using folds\n",
    "    df_valid = df[df.kfold == fold].reset_index(drop=True)\n",
    "    # get training data\n",
    "    x_train = df_train[features].values\n",
    "    # get validation data\n",
    "    x_valid = df_valid[features].values\n",
    "    # initialize xgboost model\n",
    "    model = xgb.XGBClassifier(\n",
    "    n_jobs=-1\n",
    "    )\n",
    "    # fit model on training data (ohe)\n",
    "    model.fit(x_train, df_train.income.values)\n",
    "    # predict on validation data\n",
    "    # we need the probability values as we are calculating AUC\n",
    "    # we will use the probability of 1s\n",
    "    valid_preds = model.predict_proba(x_valid)[:, 1]\n",
    "    # get roc auc score\n",
    "    auc = metrics.roc_auc_score(df_valid.income.astype(int).values, valid_preds)\n",
    "    # print auc\n",
    "    print(f\"Fold = {fold}, AUC = {auc}\")\n",
    "if __name__ == \"__main__\":\n",
    "    for fold_ in range(5):\n",
    "        run(fold_)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "b0099b8a-84c1-4cf2-bacd-51dd3e9ef71a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/12/psznqclx2xgg8vrwnyfm9r6h0000gn/T/ipykernel_3817/63061025.py:26: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '['4' '5' '9' ... '6' '10' '10']' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  df.loc[:, col] = df[col].astype(str).fillna(\"NONE\")\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"/Users/akhichoudhary/STATS/Thinkstats/Thinkstats2_exercise/Thinkstats/Approach any problem with ml/mnist_classifier/input/adult_folds.csv\")\n",
    "    # list of numerical columns\n",
    "num_cols = [\n",
    "    \"fnlwgt\",\n",
    "    \"age\",\n",
    "    \"capital_gain\",\n",
    "    \"capital_loss\",\n",
    "    \"hours_per_week\"\n",
    "    ]\n",
    "    # map targets to 0s and 1s\n",
    "target_mapping = {\n",
    "    \"<=50K\": 0,\n",
    "    \">50K\": 1\n",
    "    }\n",
    "df.loc[:, \"income\"] = df.income.map(target_mapping)\n",
    "    # all columns are features except kfold & income columns\n",
    "features = [\n",
    "    f for f in df.columns if f not in (\"kfold\", \"income\")\n",
    "    ]\n",
    "    # fill all NaN values with NONE\n",
    "    # note that I am converting all columns to \"strings\"\n",
    "    # it doesnt matter because all are categories\n",
    "for col in features:\n",
    "    # do not encode the numerical columns\n",
    "    if col not in num_cols:\n",
    "        df.loc[:, col] = df[col].astype(str).fillna(\"NONE\")\n",
    "    # now its time to label encode the features\n",
    "for col in features:\n",
    "    if col not in num_cols:\n",
    "    # initialize LabelEncoder for each feature column\n",
    "        lbl = preprocessing.LabelEncoder()\n",
    "    # fit label encoder on all data\n",
    "        lbl.fit(df[col])\n",
    "    # transform all the data\n",
    "        df.loc[:, col] = lbl.transform(df[col])\n",
    "    # get training data using folds\n",
    "df_train = df[df.kfold != 0].reset_index(drop=True)\n",
    "    # get validation data using folds\n",
    "df_valid = df[df.kfold == 0].reset_index(drop=True)\n",
    "    # get training data\n",
    "x_train = df_train[features].values\n",
    "    # get validation data\n",
    "x_valid = df_valid[features].values\n",
    "    # initialize xgboost model\n",
    "model = xgb.XGBClassifier(\n",
    "    n_jobs=-1\n",
    "    )\n",
    "    # fit model on training data (ohe)\n",
    "model.fit(x_train, df_train.income.values)\n",
    "    # predict on validation data\n",
    "    # we need the probability values as we are calculating AUC\n",
    "    # we will use the probability of 1s\n",
    "valid_preds = model.predict_proba(x_valid)[:, 1]\n",
    "    # get roc auc score\n",
    "auc = metrics.roc_auc_score(df_valid.income.astype(int).values, valid_preds)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "b4126f58-5fed-4982-9704-21d051125b05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 3, 4])"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.kfold.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "c4307e7e-ea7d-42e2-8b87-59515d01ed95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([20, 4, 366929, 15, 1, 4, 1, 3, 4, 0, 0, 0, 35, 39], dtype=object)"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "20584ee3-6221-4ecb-8b80-516856872974",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9.1151660e-04, 1.1261039e-02, 5.8521949e-02, ..., 9.9759799e-01,\n",
       "       4.9624354e-01, 1.3435982e-01], dtype=float32)"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_preds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "085ab1e2-f383-418e-bd76-4d769ebf9418",
   "metadata": {},
   "source": [
    "### 4 lbl_xgb_num_feat.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "6bc2b908-36ce-4194-86dd-d294e1a165d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 2, 3, 4), (1, 2, 3, 5), (1, 2, 4, 5), (1, 3, 4, 5), (2, 3, 4, 5)]"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import itertools\n",
    "list(itertools.combinations([1,2,3,4,5], 4))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "1b692367-7dcd-425d-9399-089ad86d980b",
   "metadata": {},
   "source": [
    "This is a very naïve way of creating features from categorical columns. One should\n",
    "take a look at the data and see which combinations make the most sense. If you use\n",
    "this method, you might end up creating a lot of features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "044bddaf-7dd0-43b1-8ead-f19f7f05a842",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/12/psznqclx2xgg8vrwnyfm9r6h0000gn/T/ipykernel_3817/3234523907.py:57: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '['4' '5' '9' ... '6' '10' '10']' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  df.loc[:, col] = df[col].astype(str).fillna(\"NONE\")\n",
      "/var/folders/12/psznqclx2xgg8vrwnyfm9r6h0000gn/T/ipykernel_3817/3234523907.py:57: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '['0' '0' '0' ... '0' '0' '6514']' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  df.loc[:, col] = df[col].astype(str).fillna(\"NONE\")\n",
      "/var/folders/12/psznqclx2xgg8vrwnyfm9r6h0000gn/T/ipykernel_3817/3234523907.py:57: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '['0' '0' '0' ... '0' '0' '0']' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  df.loc[:, col] = df[col].astype(str).fillna(\"NONE\")\n",
      "/var/folders/12/psznqclx2xgg8vrwnyfm9r6h0000gn/T/ipykernel_3817/3234523907.py:57: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '['30' '50' '40' ... '15' '25' '40']' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  df.loc[:, col] = df[col].astype(str).fillna(\"NONE\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold = 0, AUC = 0.9175999363682679\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/12/psznqclx2xgg8vrwnyfm9r6h0000gn/T/ipykernel_3817/3234523907.py:57: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '['4' '5' '9' ... '6' '10' '10']' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  df.loc[:, col] = df[col].astype(str).fillna(\"NONE\")\n",
      "/var/folders/12/psznqclx2xgg8vrwnyfm9r6h0000gn/T/ipykernel_3817/3234523907.py:57: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '['0' '0' '0' ... '0' '0' '6514']' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  df.loc[:, col] = df[col].astype(str).fillna(\"NONE\")\n",
      "/var/folders/12/psznqclx2xgg8vrwnyfm9r6h0000gn/T/ipykernel_3817/3234523907.py:57: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '['0' '0' '0' ... '0' '0' '0']' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  df.loc[:, col] = df[col].astype(str).fillna(\"NONE\")\n",
      "/var/folders/12/psznqclx2xgg8vrwnyfm9r6h0000gn/T/ipykernel_3817/3234523907.py:57: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '['30' '50' '40' ... '15' '25' '40']' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  df.loc[:, col] = df[col].astype(str).fillna(\"NONE\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold = 1, AUC = 0.9284099903614358\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/12/psznqclx2xgg8vrwnyfm9r6h0000gn/T/ipykernel_3817/3234523907.py:57: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '['4' '5' '9' ... '6' '10' '10']' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  df.loc[:, col] = df[col].astype(str).fillna(\"NONE\")\n",
      "/var/folders/12/psznqclx2xgg8vrwnyfm9r6h0000gn/T/ipykernel_3817/3234523907.py:57: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '['0' '0' '0' ... '0' '0' '6514']' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  df.loc[:, col] = df[col].astype(str).fillna(\"NONE\")\n",
      "/var/folders/12/psznqclx2xgg8vrwnyfm9r6h0000gn/T/ipykernel_3817/3234523907.py:57: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '['0' '0' '0' ... '0' '0' '0']' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  df.loc[:, col] = df[col].astype(str).fillna(\"NONE\")\n",
      "/var/folders/12/psznqclx2xgg8vrwnyfm9r6h0000gn/T/ipykernel_3817/3234523907.py:57: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '['30' '50' '40' ... '15' '25' '40']' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  df.loc[:, col] = df[col].astype(str).fillna(\"NONE\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold = 2, AUC = 0.9231155523495806\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/12/psznqclx2xgg8vrwnyfm9r6h0000gn/T/ipykernel_3817/3234523907.py:57: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '['4' '5' '9' ... '6' '10' '10']' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  df.loc[:, col] = df[col].astype(str).fillna(\"NONE\")\n",
      "/var/folders/12/psznqclx2xgg8vrwnyfm9r6h0000gn/T/ipykernel_3817/3234523907.py:57: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '['0' '0' '0' ... '0' '0' '6514']' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  df.loc[:, col] = df[col].astype(str).fillna(\"NONE\")\n",
      "/var/folders/12/psznqclx2xgg8vrwnyfm9r6h0000gn/T/ipykernel_3817/3234523907.py:57: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '['0' '0' '0' ... '0' '0' '0']' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  df.loc[:, col] = df[col].astype(str).fillna(\"NONE\")\n",
      "/var/folders/12/psznqclx2xgg8vrwnyfm9r6h0000gn/T/ipykernel_3817/3234523907.py:57: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '['30' '50' '40' ... '15' '25' '40']' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  df.loc[:, col] = df[col].astype(str).fillna(\"NONE\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold = 3, AUC = 0.9250529398652665\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/12/psznqclx2xgg8vrwnyfm9r6h0000gn/T/ipykernel_3817/3234523907.py:57: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '['4' '5' '9' ... '6' '10' '10']' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  df.loc[:, col] = df[col].astype(str).fillna(\"NONE\")\n",
      "/var/folders/12/psznqclx2xgg8vrwnyfm9r6h0000gn/T/ipykernel_3817/3234523907.py:57: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '['0' '0' '0' ... '0' '0' '6514']' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  df.loc[:, col] = df[col].astype(str).fillna(\"NONE\")\n",
      "/var/folders/12/psznqclx2xgg8vrwnyfm9r6h0000gn/T/ipykernel_3817/3234523907.py:57: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '['0' '0' '0' ... '0' '0' '0']' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  df.loc[:, col] = df[col].astype(str).fillna(\"NONE\")\n",
      "/var/folders/12/psznqclx2xgg8vrwnyfm9r6h0000gn/T/ipykernel_3817/3234523907.py:57: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '['30' '50' '40' ... '15' '25' '40']' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  df.loc[:, col] = df[col].astype(str).fillna(\"NONE\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold = 4, AUC = 0.922317068514299\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "from sklearn import metrics\n",
    "from sklearn import preprocessing\n",
    "def feature_engineering(df, cat_cols):\n",
    "    \"\"\"\n",
    "    This function is used for feature engineering\n",
    "    :param df: the pandas dataframe with train/test data\n",
    "    :param cat_cols: list of categorical columns\n",
    "    :return: dataframe with new features\n",
    "    \"\"\"\n",
    "    # this will create all 2-combinations of values\n",
    "    # in this list\n",
    "    # for example:\n",
    "    # list(itertools.combinations([1,2,3], 2)) will return\n",
    "    # [(1, 2), (1, 3), (2, 3)]\n",
    "    combi = list(itertools.combinations(cat_cols, 2))\n",
    "    for c1, c2 in combi:\n",
    "        df.loc[:,c1 + \"_\" + c2] = df[c1].astype(str) + \"_\" + df[c2].astype(str)\n",
    "    return df\n",
    "    \n",
    "def run(fold):\n",
    "    # load the full training data with folds\n",
    "    df = pd.read_csv(\"/Users/akhichoudhary/STATS/Thinkstats/Thinkstats2_exercise/Thinkstats/Approach any problem with ml/mnist_classifier/input/adult_folds.csv\")\n",
    "    # list of numerical columns\n",
    "    num_cols = [\n",
    "    \"fnlwgt\",\n",
    "    \"age\",\n",
    "    \"capital.gain\",\n",
    "    \"capital.loss\",\n",
    "    \"hours.per.week\"\n",
    "    ]\n",
    "    # map targets to 0s and 1s\n",
    "    target_mapping = {\n",
    "    \"<=50K\": 0,\n",
    "    \">50K\": 1\n",
    "    }\n",
    "    df.loc[:, \"income\"] = df.income.map(target_mapping)\n",
    "    # list of categorical columns for feature engineering\n",
    "    cat_cols = [\n",
    "    c for c in df.columns if c not in num_cols\n",
    "    and c not in (\"kfold\", \"income\")\n",
    "    ]\n",
    "    # add new features\n",
    "    df = feature_engineering(df, cat_cols)\n",
    "    # all columns are features except kfold & income columns\n",
    "    features = [\n",
    "    f for f in df.columns if f not in (\"kfold\", \"income\")\n",
    "    ]\n",
    "    # fill all NaN values with NONE\n",
    "    # note that I am converting all columns to \"strings\"\n",
    "    # it doesnt matter because all are categories\n",
    "    for col in features:\n",
    "    # do not encode the numerical columns\n",
    "        if col not in num_cols:\n",
    "            df.loc[:, col] = df[col].astype(str).fillna(\"NONE\")\n",
    "    # now its time to label encode the features\n",
    "    for col in features:\n",
    "        if col not in num_cols:\n",
    "    # initialize LabelEncoder for each feature column\n",
    "            lbl = preprocessing.LabelEncoder()\n",
    "    # fit label encoder on all data\n",
    "            lbl.fit(df[col])\n",
    "    # transform all the data\n",
    "            df.loc[:, col] = lbl.transform(df[col])\n",
    "    # get training data using folds\n",
    "            df_train = df[df.kfold != fold].reset_index(drop=True)\n",
    "    # get validation data using folds\n",
    "    df_valid = df[df.kfold == fold].reset_index(drop=True)\n",
    "    # get training data\n",
    "    x_train = df_train[features].values\n",
    "    # get validation data\n",
    "    x_valid = df_valid[features].values\n",
    "    # initialize xgboost model\n",
    "    model = xgb.XGBClassifier(\n",
    "    n_jobs=-1\n",
    "    )\n",
    "    # fit model on training data (ohe)\n",
    "    model.fit(x_train, df_train.income.astype(int).values)\n",
    "    # predict on validation data\n",
    "    # we need the probability values as we are calculating AUC\n",
    "    # we will use the probability of 1s\n",
    "    valid_preds = model.predict_proba(x_valid)[:, 1]\n",
    "    # get roc auc score\n",
    "    auc = metrics.roc_auc_score(df_valid.income.astype(int).values, valid_preds)\n",
    "    # print auc\n",
    "    print(f\"Fold = {fold}, AUC = {auc}\")\n",
    "if __name__ == \"__main__\":\n",
    "    for fold_ in range(5):\n",
    "        run(fold_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee77726c-1bc4-446a-b921-844a101b9d79",
   "metadata": {},
   "source": [
    "### 4. target_encoding"
   ]
  },
  {
   "cell_type": "raw",
   "id": "a687577e-3280-4ee9-82a4-29b83fd73706",
   "metadata": {},
   "source": [
    "One more way of feature engineering from categorical features is to use target encoding.\n",
    "you must be very careful\n",
    "when using target encoding as it is too prone to overfitting. When we use target\n",
    "encoding, it’s better to use some kind of smoothing or adding noise in the encoded\n",
    "values. Scikit-learn has contrib repository which has target encoding with\n",
    "smoothing, or you can create your own smoothing. Smoothing introduces some\n",
    "kind of regularization that helps with not overfitting the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "a1012fd0-56a5-4ed1-99a9-5e78b79ab0a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_dfs=[]\n",
    "for column in features:\n",
    "    # create dict of category:mean target\n",
    "        mapping_dict = dict(df_train.groupby(column)[\"income\"].mean())\n",
    "    # column_enc is the new column we have with mean encoding\n",
    "        df_valid.loc[:, column + \"_enc\"] = df_valid[column].map(mapping_dict)\n",
    "    # append to our list of encoded validation dataframes\n",
    "        encoded_dfs.append(df_valid)\n",
    "    # create full data frame again and return\n",
    "encoded_df = pd.concat(encoded_dfs, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "bcbfa7fb-62f6-4545-abbe-e06fb0b946d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['workclass',\n",
       " 'education',\n",
       " 'education_num',\n",
       " 'marital_status',\n",
       " 'occupation',\n",
       " 'relationship',\n",
       " 'race',\n",
       " 'sex',\n",
       " 'native_country']"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = [f for f in df.columns if f not in (\"kfold\", \"income\") and f not in num_cols]\n",
    "features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "722431c6-a3c4-4cf7-afbe-4b238865c4af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 0.07181571815718157,\n",
       " 1: 0.052854122621564484,\n",
       " 2: 0.07602339181286549,\n",
       " 3: 0.036231884057971016,\n",
       " 4: 0.04428044280442804,\n",
       " 5: 0.06679764243614932,\n",
       " 6: 0.05555555555555555,\n",
       " 7: 0.23372093023255813,\n",
       " 8: 0.2621184919210054,\n",
       " 9: 0.41343910405972933,\n",
       " 10: 0.7307692307692307,\n",
       " 11: 0.15975975975975976,\n",
       " 12: 0.5555555555555556,\n",
       " 13: 0.0,\n",
       " 14: 0.740343347639485,\n",
       " 15: 0.19033078880407125}"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict(df_train.groupby('education')[\"income\"].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "daf98535-e058-450f-8319-4055734813b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(df_train['education'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "2824e031-fb77-4ec0-9274-1c9945eeb24e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 0.4516251302947029,\n",
       " 1: 0.10097524381095274,\n",
       " 2: 0.03841229193341869,\n",
       " 3: 0.012051155927201181,\n",
       " 4: 0.06165632980663991,\n",
       " 5: 0.47101449275362317}"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict(df_train.groupby('relationship')[\"income\"].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "aa2b22cb-32dd-4ca9-81e6-8f8010758ab1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 3, 4, 5, 0, 2], dtype=object)"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['relationship'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "237a3247-5358-465b-927f-83b784601a43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       0.400000\n",
       "1       0.288136\n",
       "2       0.400000\n",
       "3       0.400000\n",
       "4       0.243644\n",
       "          ...   \n",
       "6508    0.243644\n",
       "6509    0.243644\n",
       "6510    0.306667\n",
       "6511    0.306667\n",
       "6512    0.400000\n",
       "Name: relationship, Length: 6513, dtype: float64"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_valid['relationship'].map(mapping_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "5d457579-d49a-454a-9aaa-78d24c5e2e3d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>relationship</th>\n",
       "      <th>relationship_enc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.100975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>0.012051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0.100975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0.100975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0.451625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6508</th>\n",
       "      <td>0</td>\n",
       "      <td>0.451625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6509</th>\n",
       "      <td>0</td>\n",
       "      <td>0.451625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6510</th>\n",
       "      <td>5</td>\n",
       "      <td>0.471014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6511</th>\n",
       "      <td>5</td>\n",
       "      <td>0.471014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6512</th>\n",
       "      <td>1</td>\n",
       "      <td>0.100975</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>58617 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     relationship  relationship_enc\n",
       "0               1          0.100975\n",
       "1               3          0.012051\n",
       "2               1          0.100975\n",
       "3               1          0.100975\n",
       "4               0          0.451625\n",
       "...           ...               ...\n",
       "6508            0          0.451625\n",
       "6509            0          0.451625\n",
       "6510            5          0.471014\n",
       "6511            5          0.471014\n",
       "6512            1          0.100975\n",
       "\n",
       "[58617 rows x 2 columns]"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_df[['relationship','relationship_enc']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "c607b395-48bc-4cc9-a42a-2cc87c4d819b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/12/psznqclx2xgg8vrwnyfm9r6h0000gn/T/ipykernel_3817/1108670960.py:49: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '['4' '5' '9' ... '6' '10' '10']' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  df.loc[:, col] = df[col].astype(str).fillna(\"NONE\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold = 0, AUC = 0.9188869448724375\n",
      "Fold = 1, AUC = 0.9210489110692821\n",
      "Fold = 2, AUC = 0.9209201732877618\n",
      "Fold = 3, AUC = 0.9233067885831516\n",
      "Fold = 4, AUC = 0.9134663460347732\n"
     ]
    }
   ],
   "source": [
    "# target_encoding.py\n",
    "# One more way of feature engineering from categorical features is to use target encoding.\n",
    "# you must be very careful\n",
    "# when using target encoding as it is too prone to overfitting. When we use target\n",
    "# encoding, it’s better to use some kind of smoothing or adding noise in the encoded\n",
    "# values. Scikit-learn has contrib repository which has target encoding with\n",
    "# smoothing, or you can create your own smoothing. Smoothing introduces some\n",
    "# kind of regularization that helps with not overfitting the model.\n",
    "\n",
    "# ========    used mean. You can use mean, median, standard deviation or any other function of targets. ==========*******\n",
    "# what's going on 💡\n",
    "# - The dataset of 100 rows is split into 5 folds → each fold has 80 train + 20 valid rows.\n",
    "# - For each fold, we compute the mean of Income grouped by categorical column on the train set.\n",
    "# - This encoding is then mapped onto the 20 validation rows and stored in an encoded dataset.\n",
    "# - After all 5 folds, the encoded dataset has 100 rows (all validation parts combined), ready for the run function. ✅\n",
    "\n",
    "# target_encoding.py\n",
    "import copy\n",
    "import pandas as pd\n",
    "from sklearn import metrics\n",
    "from sklearn import preprocessing\n",
    "import xgboost as xgb\n",
    "\n",
    "def mean_target_encoding(data):\n",
    "    # make a copy of dataframe\n",
    "    df = copy.deepcopy(data)\n",
    "    # list of numerical columns\n",
    "    num_cols = [\n",
    "    \"fnlwgt\",\n",
    "    \"age\",\n",
    "    \"capital_gain\",\n",
    "    \"capital_loss\",\n",
    "    \"hours_per_week\"\n",
    "    ]\n",
    "    # map targets to 0s and 1s\n",
    "    target_mapping = {\n",
    "    \"<=50K\": 0,\n",
    "    \">50K\": 1\n",
    "    }\n",
    "    df.loc[:, \"income\"] = df.income.map(target_mapping)\n",
    "    # all columns are features except income and kfold columns\n",
    "    features = [f for f in df.columns if f not in (\"kfold\", \"income\") and f not in num_cols]\n",
    "    # fill all NaN values with NONE\n",
    "    # note that I am converting all columns to \"strings\"\n",
    "    # it doesnt matter because all are categories\n",
    "    for col in features:\n",
    "    # do not encode the numerical columns\n",
    "        if col not in num_cols:\n",
    "            df.loc[:, col] = df[col].astype(str).fillna(\"NONE\")\n",
    "    # now its time to label encode the features\n",
    "    for col in features:\n",
    "        if col not in num_cols:\n",
    "    # initialize LabelEncoder for each feature column\n",
    "            lbl = preprocessing.LabelEncoder()\n",
    "    # fit label encoder on all data\n",
    "            lbl.fit(df[col])\n",
    "    # transform all the data\n",
    "            df.loc[:, col] = lbl.transform(df[col])\n",
    "    # a list to store 5 validation dataframes\n",
    "    encoded_dfs = []\n",
    "    # go over all folds\n",
    "    for fold in range(5):\n",
    "    # fetch training and validation data\n",
    "        df_train = df[df.kfold != fold].reset_index(drop=True)\n",
    "        df_valid = df[df.kfold == fold].reset_index(drop=True)\n",
    "        # for all feature columns, i.e. categorical columns\n",
    "        for column in features:\n",
    "        # create dict of category:mean target\n",
    "            mapping_dict = dict(df_train.groupby(column)[\"income\"].mean())\n",
    "            # column_enc is the new column we have with mean encoding\n",
    "            df_valid.loc[:, column + \"_enc\"] = df_valid[column].map(mapping_dict)\n",
    "            # append to our list of encoded validation dataframes\n",
    "        encoded_dfs.append(df_valid)\n",
    "            # create full data frame again and return\n",
    "    encoded_df = pd.concat(encoded_dfs, axis=0)\n",
    "    return encoded_df\n",
    "    \n",
    "def run(df, fold):\n",
    "    # note that folds are same as before\n",
    "    # get training data using folds\n",
    "    df_train = df[df.kfold != fold].reset_index(drop=True)\n",
    "    # get validation data using folds\n",
    "    df_valid = df[df.kfold == fold].reset_index(drop=True)\n",
    "\n",
    "    # all columns are features except income and kfold columns\n",
    "    features = [f for f in df.columns if f not in (\"kfold\", \"income\")]\n",
    "    # scale training data\n",
    "    x_train = df_train[features].values\n",
    "    # scale validation data\n",
    "    x_valid = df_valid[features].values\n",
    "    # initialize xgboost model\n",
    "    model = xgb.XGBClassifier(n_jobs=-1,max_depth=7)\n",
    "    # fit model on training data (ohe)\n",
    "    model.fit(x_train, df_train.income.astype(int).values)\n",
    "    # predict on validation data\n",
    "    # we need the probability values as we are calculating AUC\n",
    "    # we will use the probability of 1s\n",
    "    valid_preds = model.predict_proba(x_valid)[:, 1]\n",
    "    # get roc auc score\n",
    "    auc = metrics.roc_auc_score(df_valid.income.astype(int).values, valid_preds)\n",
    "    # print auc\n",
    "    print(f\"Fold = {fold}, AUC = {auc}\")\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    # read data\n",
    "    df=pd.read_csv('/Users/akhichoudhary/STATS/Thinkstats/Thinkstats2_exercise/Thinkstats/Approach any problem with ml/mnist_classifier/input/adult_folds.csv')\n",
    "    # create mean target encoded categories and\n",
    "    # munge data\n",
    "    df = mean_target_encoding(df)\n",
    "    # run training and validation for 5 folds\n",
    "    for fold_ in range(5):\n",
    "        run(df, fold_)\n",
    "\n",
    "# 🧠\n",
    "# -If you had taken the mean of the validation set and then used it to encode the training set, it would be like “peeking into the exam answers before writing the exam” → the model would see information from data it should not have access to during training.\n",
    "# - That leakage means:\n",
    "# - The train set would be influenced by future/hidden info.\n",
    "# - Model would show inflated performance on validation but fail on unseen/test data.\n",
    "# - This is classic data leakage → overfitting.\n",
    "# - 👉 Correct way: Always calculate encoding from train only, then apply to valid/test\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8941fb7-7a5c-456a-a842-1c8339fbd76b",
   "metadata": {},
   "source": [
    "### 5. entity_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f8f3ad1-0c7e-4855-a925-5aa3bdba0274",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import joblib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import metrics ,preprocessing\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.model import Model,load_model\n",
    "from tensorflow.keras import callbacks\n",
    "from tensorflow.keras import backend as k\n",
    "from tensorflow.keras import utils\n",
    "\n",
    "def create_model(data,catcols):\n",
    "    inputs=[]\n",
    "    outputs=[]\n",
    "    for c in catcols:\n",
    "        num_unique_values=int(data[c].nunique())\n",
    "        embed_din=int(min(np.ceil((num_unique_values)/2),50))\n",
    "        inp=layers.Input(shape=(1,))\n",
    "        out=layers.Embedding(num_unique_values+1,embed_dim,name=c)(inp)\n",
    "        \n",
    "                      \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
