{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21fca4b3-e935-43bc-9bc1-61d710caa9b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3811a7ee-23a5-4be2-a4f2-e179e9630910",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/akhichoudhary/STATS/Thinkstats/Thinkstats2_exercise/Thinkstats/Approach any problem with ml\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f77896b4-af67-4422-a296-3ca2226dd4f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "file_path = '/Users/akhichoudhary/STATS/Thinkstats/Thinkstats2_exercise/Thinkstats/Approach any problem with ml/car-in-the-dat.zip'\n",
    "print(os.path.exists(file_path))  # Should return True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1759db9b-71ea-4d30-add1-0fcd80900cfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import zipfile\n",
    "# import pandas as pd\n",
    "\n",
    "# df=pd.read_csv('/Users/akhichoudhary/STATS/Thinkstats/Thinkstats2_exercise/Thinkstats/Approach any problem with ml/data/train.csv')\n",
    "\n",
    "# or-------\n",
    "\n",
    "# # Path to the ZIP folder\n",
    "# zip_path = '/Users/akhichoudhary/STATS/Thinkstats/Thinkstats2_exercise/Thinkstats/Approach any problem with ml/cat-in-the-dat.zip'\n",
    "\n",
    "# # Open the zip and list contents\n",
    "# with zipfile.ZipFile(zip_path, 'r') as z:\n",
    "#     print(\"Files in ZIP:\", z.namelist())  # View files like 'train.csv', 'test.csv'\n",
    "\n",
    "#     # Load specific CSVs\n",
    "#     with z.open('train.csv') as f:\n",
    "#         train_df = pd.read_csv(f)\n",
    "\n",
    "#     with z.open('test.csv') as f:\n",
    "#         test_df = pd.read_csv(f)\n",
    "\n",
    "# # Now you can use train_df and test_df as usual\n",
    "# # print(train_df.head())\n",
    "# # print(test_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e03b6907-55e6-46a7-a008-8a7db41b6b80",
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping={\n",
    "    \"Freezing\": 0,\n",
    "    \"Warm\": 1,\n",
    "    \"Cold\": 2,\n",
    "    \"Boiling Hot\": 3,\n",
    "    \"Hot\": 4,\n",
    "    \"Lava Hot\": 5\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "54d48562-1cf7-46b6-96f8-5a3eb367b85c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ord_2\n",
       "Freezing       99816\n",
       "Lava Hot       63908\n",
       "Boiling Hot    60627\n",
       "Cold           33768\n",
       "Hot            22227\n",
       "Warm           19654\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.ord_2.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "468fbed4-1268-4ff7-83c3-6ca31e439f7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.loc[:,\"ord_2\"]=train_df.ord_2.map(mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c9bf7cd7-6080-47bd-8bb1-7deba3f5a535",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ord_2\n",
       "0    99816\n",
       "5    63908\n",
       "3    60627\n",
       "2    33768\n",
       "4    22227\n",
       "1    19654\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.ord_2.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b733e69b-c2b1-487f-8bc6-de1119276711",
   "metadata": {},
   "source": [
    "## ~ LabelEncoder,OneHotEncoder,Binarization\n",
    "- above same encoding into numerical value can be done by LabelEncoder from scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d98e5baa-1255-47b0-8dc9-9a09a679dc6f",
   "metadata": {},
   "source": [
    "### Label Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5c498bab-5be5-4c5b-a64a-2d71137fe765",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "df=pd.read_csv('/Users/akhichoudhary/STATS/Thinkstats/Thinkstats2_exercise/Thinkstats/Approach any problem with ml/data/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0c39969d-9144-4ea8-945b-9906092ac7ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[:,\"ord_2\"]=df.ord_2.fillna(\"NONE\")\n",
    "# LabelEncoder from scikit-learn does not handle NaN values, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5b95b182-b75f-4164-9523-3a9ec3065b22",
   "metadata": {},
   "outputs": [],
   "source": [
    "lbl_enc=preprocessing.LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c54cadf0-1f1f-467d-a1e7-77597bb8b2f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit label encoder and transform values on ord_2 column\n",
    "# P.S: do not use this directly. fit first, then transform\n",
    "df.loc[:,\"ord_2\"]=lbl_enc.fit_transform(df.ord_2.values)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "61396b4d-433b-481f-8cd2-2a24a57ee0a2",
   "metadata": {},
   "source": [
    "# labelEncoder can be used \n",
    "• Decision trees\n",
    "• Random forest\n",
    "• Extra Trees\n",
    "• Or any kind of boosted trees model\n",
    "o XGBoost\n",
    "o GBM\n",
    "o LightGBM\n",
    "This type of encoding cannot be used in linear models, support vector machines or\n",
    "neural networks as they expect data to be normalized (or standardized)."
   ]
  },
  {
   "cell_type": "raw",
   "id": "cf7ccbe4-a870-4ae3-a1e8-f5ad7e1ec73c",
   "metadata": {},
   "source": [
    "✅ What it's saying:\n",
    "1. For Tree-Based Models (e.g., Decision Trees, Random Forest, XGBoost, LightGBM):\n",
    "You can use Label Encoding or even leave NaNs in some cases.\n",
    "\n",
    "Tree models do not require one-hot or binarized encoding because they can naturally handle splits based on categorical values.\n",
    "\n",
    "That’s why it's okay to use LabelEncoder (after handling NaNs properly) or even ordinal encoding.\n",
    "\n",
    "2. For Linear Models / SVMs / Neural Networks:\n",
    "You should not use Label Encoding because it introduces an artificial ordinal relationship between categories (e.g., A=0, B=1, C=2 suggests C > B > A which may not be true).\n",
    "\n",
    "Instead, you should use One-Hot Encoding or Binarization.\n",
    "\n",
    "Binarization is converting each category into a binary format (e.g., A → [0 0 1], B → [0 1 0], C → [1 0 0]).\n",
    "\n",
    "This is often done in sparse format to save memory, since many values will be 0.\n",
    "\n",
    "❓ So is it suggesting binarization for linear models?\n",
    "Yes. Specifically, it is saying:\n",
    "\n",
    "Use binarization/one-hot encoding for models that require numerical input to be normalized:\n",
    "Linear Regression, Logistic Regression, Support Vector Machines (SVM), and Neural Networks.\n",
    "\n",
    "Continue with Label Encoding or Ordinal Encoding for tree-based models, which can handle this directly."
   ]
  },
  {
   "cell_type": "raw",
   "id": "bc854f6f-709b-4af9-b80d-fd4a41fc03ba",
   "metadata": {},
   "source": [
    "| Model Type          | Recommended Encoding     | Notes                             |\n",
    "| ------------------- | ------------------------ | --------------------------------- |\n",
    "| Decision Tree       | Label Encoding / Ordinal | Can handle NaNs                   |\n",
    "| Random Forest       | Label Encoding / Ordinal | Can handle categories             |\n",
    "| XGBoost / LightGBM  | Label Encoding / Ordinal | Best with category-aware encoding |\n",
    "| Linear Regression   | One-Hot / Binarization   | Needs numeric & normalized data   |\n",
    "| Logistic Regression | One-Hot / Binarization   | Same                              |\n",
    "| SVM                 | One-Hot / Binarization   | Same                              |\n",
    "| Neural Networks     | One-Hot / Binarization   | Same                              |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb35a159-2770-43ee-86db-46f16262f249",
   "metadata": {},
   "source": [
    "-  checking the bytes used by different techniques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a7a8df34-fa3f-4716-bb2f-ad26247e5682",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "example=np.array([\n",
    "    [0,0,1],\n",
    "    [1,0,0],\n",
    "    [1,0,1]]\n",
    ")\n",
    "print(example.nbytes)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "8a47e46a-ab83-4417-9d5f-1b2a756e5149",
   "metadata": {},
   "source": [
    "One way to\n",
    "represent this matrix only with ones would be some kind of dictionary method in\n",
    "which keys are indices of rows and columns and value is 1:\n",
    "══════════════════\n",
    "(0, 2) 1\n",
    "(1, 0) 1\n",
    "(2, 0) 1\n",
    "(2, 2) 1\n",
    "══════════════════"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ec6c77d6-5c7b-42ad-a9b1-d520ea9cac7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32\n"
     ]
    }
   ],
   "source": [
    "from scipy import sparse\n",
    "\n",
    "example=np.array(\n",
    "    [[0, 0, 1],\n",
    "[1, 0, 0],\n",
    "[1, 0, 1]]\n",
    ")\n",
    "\n",
    "sparse_example=sparse.csr_matrix(example)\n",
    "print(sparse_example.data.nbytes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a35c3e5-ea59-442f-a07d-f663e42ef1b7",
   "metadata": {},
   "source": [
    "- The total size of the sparse csr matrix is the sum of three values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3efb6518-e8a4-43a9-8c95-df9dbb7e2b73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    sparse_example.data.nbytes +\n",
    "sparse_example.indptr.nbytes +\n",
    "sparse_example.indices.nbytes\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c1454018-0f7c-4e70-b93e-ec4b16fb7707",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of dense array: 8000000000\n",
      "Size of sparse array: 399997896\n",
      "Full size of sparse array: 600036848\n"
     ]
    }
   ],
   "source": [
    "# number of rows\n",
    "n_rows = 10000\n",
    "# number of columns\n",
    "n_cols = 100000\n",
    "# create random binary matrix with only 5% values as 1s\n",
    "example = np.random.binomial(1, p=0.05, size=(n_rows, n_cols))\n",
    "# print size in bytes\n",
    "print(f\"Size of dense array: {example.nbytes}\")\n",
    "# convert numpy array to sparse CSR matrix\n",
    "sparse_example = sparse.csr_matrix(example)\n",
    "# print size of this sparse matrix\n",
    "print(f\"Size of sparse array: {sparse_example.data.nbytes}\")\n",
    "full_size = (\n",
    "sparse_example.data.nbytes +\n",
    "sparse_example.indptr.nbytes +\n",
    "sparse_example.indices.nbytes\n",
    ")\n",
    "# print full size of this sparse matrix\n",
    "print(f\"Full size of sparse array: {full_size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4dc0d379-955f-4616-8394-145abeb6fe08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# So, dense array takes ~8000MB or approximately 8GB of memory. The sparse\n",
    "# array, on the other hand, takes only 399MB of memory.\n",
    "# And, that’s why we prefer sparse arrays over dense whenever we have a lot of zeros\n",
    "# in our features."
   ]
  },
  {
   "cell_type": "raw",
   "id": "b083ff76-3823-4e02-b2ed-4d01ad75ec1f",
   "metadata": {},
   "source": [
    "Even though the sparse representation of binarized features takes much less\n",
    "memory than its dense representation, there is another transformation for\n",
    "categorical variables that takes even less memory. This is known as One Hot\n",
    "Encoding.\n",
    "One hot encoding is a binary encoding too in the sense that there are only two\n",
    "values, 0s and 1s."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d65aa563-0337-4985-aac7-2a2b85d6479a",
   "metadata": {},
   "source": [
    "### Binarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "31eed1d8-9f71-4ee7-830a-52b183c3b953",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of dense array: 144\n",
      "Size of sparse array: 24\n",
      "Full size of sparse array: 52\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy import sparse\n",
    "# create binary matrix\n",
    "example = np.array(\n",
    "[\n",
    "[0, 0, 0, 0, 1, 0],\n",
    "[0, 1, 0, 0, 0, 0],\n",
    "[1, 0, 0, 0, 0, 0]\n",
    "]\n",
    ")\n",
    "# print size in bytes\n",
    "print(f\"Size of dense array: {example.nbytes}\")\n",
    "# convert numpy array to sparse CSR matrix\n",
    "sparse_example = sparse.csr_matrix(example)\n",
    "# print size of this sparse matrix\n",
    "print(f\"Size of sparse array: {sparse_example.data.nbytes}\")\n",
    "full_size = (\n",
    "sparse_example.data.nbytes +\n",
    "sparse_example.indptr.nbytes +\n",
    "sparse_example.indices.nbytes\n",
    ")\n",
    "# print full size of this sparse matrix\n",
    "print(f\"Full size of sparse array: {full_size}\")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "a6830866-ba05-4739-9f2d-2611d9f7cabf",
   "metadata": {},
   "source": [
    "We see that the dense array size is much larger than the one with binarization.\n",
    "However, the size of the sparse array is much less. Let’s try this with a much larger\n",
    "array. In this example, we will use OneHotEncoder from scikit-learn to transform\n",
    "our feature array with 1001 categories into dense and sparse matrices."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40695d83-b6ed-4910-9072-d7d1278f3c4d",
   "metadata": {},
   "source": [
    "### OneHotEncoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1e037532-ed0e-4c17-a64c-e67b376b7a07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of dense array: 8000000000\n",
      "Size of sparse array: 8000000\n",
      "Full size of sparse array: 16000004\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "# create random 1-d array with 1001 different categories (int)\n",
    "example = np.random.randint(1000, size=1000000)\n",
    "# initialize OneHotEncoder from scikit-learn\n",
    "# keep sparse = False to get dense array\n",
    "ohe = preprocessing.OneHotEncoder(sparse_output=False)\n",
    "# fit and transform data with dense one hot encoder\n",
    "ohe_example = ohe.fit_transform(example.reshape(-1, 1))\n",
    "# print size in bytes for dense array\n",
    "print(f\"Size of dense array: {ohe_example.nbytes}\")\n",
    "# initialize OneHotEncoder from scikit-learn\n",
    "# keep sparse = True to get sparse array\n",
    "ohe = preprocessing.OneHotEncoder(sparse_output=True)\n",
    "# fit and transform data with sparse one-hot encoder\n",
    "ohe_example = ohe.fit_transform(example.reshape(-1, 1))\n",
    "# print size of this sparse matrix\n",
    "print(f\"Size of sparse array: {ohe_example.data.nbytes}\")\n",
    "full_size = (\n",
    "ohe_example.data.nbytes +\n",
    "ohe_example.indptr.nbytes + ohe_example.indices.nbytes\n",
    ")\n",
    "# print full size of this sparse matrix\n",
    "print(f\"Full size of sparse array: {full_size}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9d3555c-e0c9-45d8-bda1-b74f2e761aa8",
   "metadata": {},
   "source": [
    "### Data manipulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "21f4ed74-f7e7-4985-b85a-f9243f58002c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         33768\n",
       "1         22227\n",
       "2         63908\n",
       "3         60627\n",
       "4         99816\n",
       "          ...  \n",
       "299995    99816\n",
       "299996    99816\n",
       "299997    60627\n",
       "299998    60627\n",
       "299999    99816\n",
       "Name: id, Length: 300000, dtype: int64"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby([\"ord_2\"])[\"id\"].transform(\"count\")\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "050d995d-b20e-46a4-8dfe-9c65e7f69514",
   "metadata": {},
   "source": [
    "It adds a new column (or Series) that shows, for each row in df, how many rows have the same ord_2 value — by counting the number of occurrences of each value in the \"ord_2\" column using the \"id\" column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "706fa7e9-56ce-45d0-8309-45fed291e553",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ord_1</th>\n",
       "      <th>ord_2</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Contributor</td>\n",
       "      <td>0</td>\n",
       "      <td>8692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Contributor</td>\n",
       "      <td>1</td>\n",
       "      <td>4842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Contributor</td>\n",
       "      <td>2</td>\n",
       "      <td>14284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Contributor</td>\n",
       "      <td>3</td>\n",
       "      <td>3122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Contributor</td>\n",
       "      <td>4</td>\n",
       "      <td>9074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Contributor</td>\n",
       "      <td>5</td>\n",
       "      <td>2857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Expert</td>\n",
       "      <td>0</td>\n",
       "      <td>4980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Expert</td>\n",
       "      <td>1</td>\n",
       "      <td>2850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Expert</td>\n",
       "      <td>2</td>\n",
       "      <td>8432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Expert</td>\n",
       "      <td>3</td>\n",
       "      <td>1887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Expert</td>\n",
       "      <td>4</td>\n",
       "      <td>5274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Expert</td>\n",
       "      <td>5</td>\n",
       "      <td>1642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Grandmaster</td>\n",
       "      <td>0</td>\n",
       "      <td>15719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Grandmaster</td>\n",
       "      <td>1</td>\n",
       "      <td>8702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Grandmaster</td>\n",
       "      <td>2</td>\n",
       "      <td>25620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Grandmaster</td>\n",
       "      <td>3</td>\n",
       "      <td>5697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Grandmaster</td>\n",
       "      <td>4</td>\n",
       "      <td>16617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Grandmaster</td>\n",
       "      <td>5</td>\n",
       "      <td>5073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Master</td>\n",
       "      <td>0</td>\n",
       "      <td>5720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Master</td>\n",
       "      <td>1</td>\n",
       "      <td>3129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Master</td>\n",
       "      <td>2</td>\n",
       "      <td>9401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Master</td>\n",
       "      <td>3</td>\n",
       "      <td>2069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Master</td>\n",
       "      <td>4</td>\n",
       "      <td>5882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Master</td>\n",
       "      <td>5</td>\n",
       "      <td>1852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Novice</td>\n",
       "      <td>0</td>\n",
       "      <td>25516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Novice</td>\n",
       "      <td>1</td>\n",
       "      <td>14245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Novice</td>\n",
       "      <td>2</td>\n",
       "      <td>42079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Novice</td>\n",
       "      <td>3</td>\n",
       "      <td>9452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Novice</td>\n",
       "      <td>4</td>\n",
       "      <td>27061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Novice</td>\n",
       "      <td>5</td>\n",
       "      <td>8230</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          ord_1  ord_2  count\n",
       "0   Contributor      0   8692\n",
       "1   Contributor      1   4842\n",
       "2   Contributor      2  14284\n",
       "3   Contributor      3   3122\n",
       "4   Contributor      4   9074\n",
       "5   Contributor      5   2857\n",
       "6        Expert      0   4980\n",
       "7        Expert      1   2850\n",
       "8        Expert      2   8432\n",
       "9        Expert      3   1887\n",
       "10       Expert      4   5274\n",
       "11       Expert      5   1642\n",
       "12  Grandmaster      0  15719\n",
       "13  Grandmaster      1   8702\n",
       "14  Grandmaster      2  25620\n",
       "15  Grandmaster      3   5697\n",
       "16  Grandmaster      4  16617\n",
       "17  Grandmaster      5   5073\n",
       "18       Master      0   5720\n",
       "19       Master      1   3129\n",
       "20       Master      2   9401\n",
       "21       Master      3   2069\n",
       "22       Master      4   5882\n",
       "23       Master      5   1852\n",
       "24       Novice      0  25516\n",
       "25       Novice      1  14245\n",
       "26       Novice      2  42079\n",
       "27       Novice      3   9452\n",
       "28       Novice      4  27061\n",
       "29       Novice      5   8230"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby(['ord_1','ord_2'])['id'].count().reset_index(name='count')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67da6fae-84eb-4e94-bb87-2818fa4d418c",
   "metadata": {},
   "source": [
    "- is used to count the number of rows (based on id) for each combination of ord_1 and ord_2 values in your DataFrame.\n",
    "- .reset_index(name=\"count\")\n",
    "Resets the index (so you get a flat DataFrame) and renames the id count column to \"count\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f839d48f-1a14-4fc8-a7b0-e629fafeb872",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    Grandmaster_1\n",
       "1    Grandmaster_3\n",
       "2         Expert_4\n",
       "3    Grandmaster_0\n",
       "4    Grandmaster_2\n",
       "Name: new feature, dtype: object"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create new feature\n",
    "df['new feature']=df.ord_1.astype(str)+\"_\"+df.ord_2.astype(str)\n",
    "df['new feature'].head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75445650-e05e-4761-a88f-29c8aad21fb5",
   "metadata": {},
   "source": [
    "#### Steps\n",
    "Whenever you get categorical variables, follow these simple steps:\n",
    "- • fill the NaN values (this is very important!)\n",
    "- • convert them to integers by applying label encoding using LabelEncoder of scikit-learn or by using a mapping dictionary. If you didn’t fill up NaN\n",
    "values with something, you might have to take care of them in this step\n",
    "- • create one-hot encoding. Yes, you can skip binarization!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6c64bfa-444b-43cc-a545-7149531cabab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "093770c9-4a63-4274-80d6-da688a3544d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e52c523c-8742-4bcb-bfd2-7ae0802dbe4a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "336a769b-4591-4682-bdbe-de250f86168d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cc1d176-74e3-48ec-bba8-ca878ba0d3ba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
